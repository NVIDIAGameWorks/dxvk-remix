/*
* Copyright (c) 2023-2024, NVIDIA CORPORATION. All rights reserved.
*
* Permission is hereby granted, free of charge, to any person obtaining a
* copy of this software and associated documentation files (the "Software"),
* to deal in the Software without restriction, including without limitation
* the rights to use, copy, modify, merge, publish, distribute, sublicense,
* and/or sell copies of the Software, and to permit persons to whom the
* Software is furnished to do so, subject to the following conditions:
*
* The above copyright notice and this permission notice shall be included in
* all copies or substantial portions of the Software.
*
* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
* IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
* FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
* THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
* LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
* FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
* DEALINGS IN THE SOFTWARE.
*/
#pragma once

#include "rtx/utility/common.slangh"
#include "rtx/utility/math.slangh"
#include "rtx/utility/packing.slangh"
#include "rtx/concept/ray/ray.h"
#include "rtx/pass/common_bindings.slangh"
#include "rtx/utility/debug_view_indices.h"

// Surface Interaction Constants

static const uint kFootprintFromRayOrigin = 0u;
static const uint kFootprintFromRayDirection = 1u;
static const uint kFootprintFromTextureCoordDiff = 2u;
static const uint kFootprintFromRayOriginClamped = 3u;

static const bool SurfaceGenerateTangents = true;
static const bool SurfaceIgnoreTangents = false;

// Surface Interaction Helper Functions

// Texture Gradient from Ray Cone Helper
// [2021, "Improved Shader and Texture Level of Detail Using Ray Cones"] (Listing 1)
// Computes the texture gradients for anisotropic texture filtering based on the intersection of a ray cone with a triangle.
// Approximates the ray cone as a cylinder based on the cone radius at the point of intersection and computes the axes of an
// ellipse formed by this cylinder's intersection with the triangle to derive the gradients from. Arguments:
// - intersectionPoint: The world space intersection point of the ray on the triangle.
// - triangleNormal: The world space normal of the triangle.
// - twoTriangleArea: Two times the world space area of the triangle (magnitude of a cross product spanning the triangle).
// - rayConeDir: The direction of the ray cone.
// - rayConeRadiusAtIntersection: The radius of the ray cone at the intersection point, typically computed as coneRadiusAtIntersection = hitT * tan(rayConeAngle) but
//   this may be approximated as coneRadiusAtIntersection = hitT * rayConeAngle when the ray cone angle is very close to 0.
// - positions: An array of positions of the triangle vertices in world space.
// - txcoords: An array of texture coordinates of the vertices of the triangle.
// - interpolatedTexCoordsAtIntersection: The interpolated texture coordinates at the intersection point.
// - texGradientX: The output for the first gradient of the texture coordinates.
// - texGradientY: The output for the second gradient of the texture coordinates.
void computeAnisotropicEllipseAxes(
  vec3 intersectionPoint, f16vec3 triangleNormal, float twoTriangleArea, f16vec3 rayConeDir,
  float16_t rayConeRadiusAtIntersection, vec3 positions[3], vec2 txcoords[3], vec2 interpolatedTexCoordsAtIntersection,
  inout vec2 texGradientX, inout vec2 texGradientY)
{
  // Compute ellipse axes.
  vec3 ellipseAxis0 = rayConeDir - dot(vec3(triangleNormal), vec3(rayConeDir)) * vec3(triangleNormal); // Project the ray direction onto the plane to find the ellipse axis.
  const vec3 rayDirPlaneProjection0 = ellipseAxis0 - dot(vec3(rayConeDir), ellipseAxis0) * vec3(rayConeDir); // Project the ellipse axis onto the plane defined by the ray cone's direction.
  ellipseAxis0 *= rayConeRadiusAtIntersection / max(0.0001, length(rayDirPlaneProjection0)); // Use similar triangles to find the scale of the axis.

  vec3 ellipseAxis1 = cross(vec3(triangleNormal), ellipseAxis0); // Find the other orthogonal ellipse axis via a cross product with the triangle's normal.
  const vec3 rayDirPlaneProjection1 = ellipseAxis1 - dot(vec3(rayConeDir), ellipseAxis1) * vec3(rayConeDir);
  ellipseAxis1 *= rayConeRadiusAtIntersection / max(0.0001, length(rayDirPlaneProjection1));

  // Compute barycentrics and texture coordinate gradients.
  const vec3 d = intersectionPoint - positions[0];
  const vec3 edge01 = positions[1] - positions[0];
  const vec3 edge02 = positions[2] - positions[0];
  const float oneOverTwoAreaTriangle = 1.0f / twoTriangleArea;

  vec3 edgeP;

  edgeP = d + ellipseAxis0;
  const float u1 = (dot(vec3(triangleNormal), cross(edgeP, edge02)) * oneOverTwoAreaTriangle);
  const float v1 = (dot(vec3(triangleNormal), cross(edge01, edgeP)) * oneOverTwoAreaTriangle);
  texGradientX = (1.0 - u1 - v1) * txcoords[0] + u1 * txcoords[1] + v1 * txcoords[2] - interpolatedTexCoordsAtIntersection;

  edgeP = d + ellipseAxis1;
  const float u2 = (dot(vec3(triangleNormal), cross(edgeP, edge02)) * oneOverTwoAreaTriangle);
  const float v2 = (dot(vec3(triangleNormal), cross(edge01, edgeP)) * oneOverTwoAreaTriangle);
  texGradientY = (1.0 - u2 - v2) * txcoords[0] + u2 * txcoords[1] + v2 * txcoords[2] - interpolatedTexCoordsAtIntersection;
}

// Surface Interaction Functions

bool isSurfaceClipped(Surface surface, MinimalSurfaceInteraction surfaceInteraction)
{
  if (!surface.isClipPlaneEnabled)
  {
    return false;
  }

  const float clipDistance = dot(surface.clipPlane.xyz, surfaceInteraction.position) + surface.clipPlane.w;

  return clipDistance < 0.0;
}
 
// <0, 1> -> <-0.5, 0.5>
vec2 texcoordToOffsetFromTextureCenter(vec2 texcoord)
{
  return texcoord - 0.5;
}

// <-0.5, 0.5> -> <0, 1>
vec2 offsetFromTextureCenterToTexcoord(vec2 offset)
{
  return offset + 0.5;
}

// Converts from <0, 1> texture space of a first cascade into <0, 1> texture space of the Nth cascade
vec2 convert1stCascadeTexCoordToTargetCascadeLevel(float rcpTargetCascadeLevelScale, vec2 texcoord)
{
  return offsetFromTextureCenterToTexcoord(rcpTargetCascadeLevelScale * texcoordToOffsetFromTextureCenter(texcoord));
}

// Converts from <0, 1> texture space of a Nth cascade into <0, 1> of a combined tiled texture space <0, 1>
vec2 convert1stCascadeTexCoordToTiledTexCoord(uvec2 cascade2DIndex, float rcpTargetCascadeLevelScale, vec2 texcoord)
{
  return cb.terrainArgs.rcpCascadeMapSize * (cascade2DIndex + convert1stCascadeTexCoordToTargetCascadeLevel(rcpTargetCascadeLevelScale, texcoord));
}

// Converts from <0, 1> texture space of a first cascade into texture coords of Nth cascade of a combined tiled texture space <0, 1>
// where cascades are stored as tiles left to right, top to bottom
void convert1stCascadeTexCoordsToTargetCascadeLevel(uint targetCascadeLevel, inout vec2 interpolatedTexcoord, inout vec2 texcoords[3])
{
  ivec2 cascade2DIndex;
  cascade2DIndex.y = targetCascadeLevel * cb.terrainArgs.rcpCascadeMapSize.x;
  cascade2DIndex.x = targetCascadeLevel - cascade2DIndex.y * cb.terrainArgs.cascadeMapSize.x;

  const float baseCascadeScale = targetCascadeLevel == cb.terrainArgs.maxCascadeLevel ? cb.terrainArgs.lastCascadeScale : 1.f;
  const float rcpTargetCascadeLevelScale = 1 / (baseCascadeScale * pow(2, targetCascadeLevel));

  interpolatedTexcoord = convert1stCascadeTexCoordToTiledTexCoord(cascade2DIndex, rcpTargetCascadeLevelScale, interpolatedTexcoord);

  [unroll]
  for (uint i = 0; i < 3; i++)
  {
    texcoords[i] = convert1stCascadeTexCoordToTiledTexCoord(cascade2DIndex, rcpTargetCascadeLevelScale, texcoords[i]);
  }
}

// Adjusts a specified set of texture coordinates and gradients with respect to specified spritesheet information.
void calcSpriteSheetAdjustment(
  inout vec2 textureCoordinates,
  inout vec2 textureGradientX,
  inout vec2 textureGradientY,
  float timeSinceStartSeconds,
  uint8_t spriteSheetRows,
  uint8_t spriteSheetCols,
  uint8_t spriteSheetFPS)
{
  // Note: Fast path for most materials which do not actually use animated spritesheets.
  if (spriteSheetFPS == 0)
  {
    return;
  }
  vec2 uvSize, uvBias;
  calcSpritesheetValues(
    timeSinceStartSeconds,
    spriteSheetRows,
    spriteSheetCols,
    spriteSheetFPS,
    uvSize,
    uvBias);

  textureCoordinates = uvBias + frac(textureCoordinates) * uvSize;
  textureGradientX *= uvSize;
  textureGradientY *= uvSize;
}

void calcSpritesheetValues(
  float timeSinceStartSeconds,
  uint8_t spriteSheetRows,
  uint8_t spriteSheetCols,
  uint8_t spriteSheetFPS,
  inout vec2 uvSize,
  inout vec2 uvBias
)
{
  const uint numSprites = spriteSheetCols * spriteSheetRows;
  // Note: timeSinceStartSeconds is clamped to (2^24 - 1) / 1000 on the CPU side so this multiplication shouldn't overflow.
  const uint frame = (uint(timeSinceStartSeconds * spriteSheetFPS)) % numSprites;

  uvSize = vec2(1.0f / spriteSheetCols, 1.0f / spriteSheetRows);
  uvBias = vec2(frame % spriteSheetCols, frame / spriteSheetCols) * uvSize;
}

SurfaceInteraction surfaceInteractionCreate<let GenerateTangents : bool>(
  Surface surface, RayInteraction rayInteraction, Ray ray,
  bool usePreviousPositions = false, uint footprintMode = kFootprintFromRayDirection)
{
  // Compute vertex indicies

  uint idx[3];

  for (uint i = 0; i < 3; i++)
  {
    const uint indexIndex = rayInteraction.primitiveIndex * 3 + i + surface.firstIndex;

    if (surface.indexBufferIndex != BINDING_INDEX_INVALID)
    {
      const uint indexBufferIndex = surface.indexBufferIndex;

      if (surface.indexStride == 4)
      {
        idx[i] = BUFFER_ARRAY(indices32, indexBufferIndex, indexIndex);
      }
      else
      {
        idx[i] = BUFFER_ARRAY(indices, indexBufferIndex, indexIndex);
      }
    }
    else
    {
      idx[i] = indexIndex;
    }
  }

  // Retrieve vertex data

  vec3 positions[3];

  if (usePreviousPositions && !surface.isStatic && surface.previousPositionBufferIndex != BINDING_INDEX_INVALID)
  {
    for (uint i = 0; i < 3; i++)
    {
      const uint currentIndex = idx[i];

      const uint previousPositionBufferIndex = surface.previousPositionBufferIndex;
      const uint previousPositionElementIndex = (currentIndex * uint(surface.positionStride) + surface.positionOffset) / 4;

      positions[i].x = BUFFER_ARRAY(geometries, previousPositionBufferIndex, previousPositionElementIndex + 0);
      positions[i].y = BUFFER_ARRAY(geometries, previousPositionBufferIndex, previousPositionElementIndex + 1);
      positions[i].z = BUFFER_ARRAY(geometries, previousPositionBufferIndex, previousPositionElementIndex + 2);
    }
  }
  else
  {
    for (uint i = 0; i < 3; i++)
    {
      const uint currentIndex = idx[i];

      // Note: Position buffer is always required for now
      // if (surface.positionBufferIndex != BINDING_INDEX_INVALID)
      {
        const uint positionBufferIndex = surface.positionBufferIndex;
        const uint positionElementIndex = (currentIndex * uint(surface.positionStride) + surface.positionOffset) / 4;

        positions[i].x = BUFFER_ARRAY(geometries, positionBufferIndex, positionElementIndex + 0);
        positions[i].y = BUFFER_ARRAY(geometries, positionBufferIndex, positionElementIndex + 1);
        positions[i].z = BUFFER_ARRAY(geometries, positionBufferIndex, positionElementIndex + 2);
      }
    }
  }

  const vec3 bary = uintToBarycentrics(rayInteraction.barycentricCoordinates);

  SurfaceInteraction surfaceInteraction;
  
  // Calculate vertex position in world space
  // Note: World space positions needed to compute the texture gradients, a bit expensive but probably easier than transforming
  // the ray direction into object space and worrying about how to transform its cone width appropriately (scales could affect it).
  // Additionally, this allows us to calculate the triangle normal in world space without having to transform an object space normal
  // into world space with a normal matrix which makes up for some of the work this does. Unfortunately the interpolated normal still
  // requires usage of a normal matrix though. World position is now also needed for the position calculation in general as it is higher
  // precision to calculate it this way on the Surface Interaction than on the Ray Interaction.

  vec3 worldPositions[3];

  if (usePreviousPositions && !surface.isStatic)
  {
    worldPositions[0] = mul(surface.prevObjectToWorld, vec4(positions[0], 1.0f));
    worldPositions[1] = mul(surface.prevObjectToWorld, vec4(positions[1], 1.0f));
    worldPositions[2] = mul(surface.prevObjectToWorld, vec4(positions[2], 1.0f));
  }
  else
  {
    worldPositions[0] = mul(surface.objectToWorld, vec4(positions[0], 1.0f));
    worldPositions[1] = mul(surface.objectToWorld, vec4(positions[1], 1.0f));
    worldPositions[2] = mul(surface.objectToWorld, vec4(positions[2], 1.0f));
  }

  // Calculate the approximate position error in object space
  surfaceInteraction.positionError = max(
    calculatePositionError(positions[0]),
    max(calculatePositionError(positions[1]),
        calculatePositionError(positions[2])));

  // Compute world position
  // Note: This calculation is done with world space positions rather than model space positions and transforming it to world space
  // as we have these world space positions available to begin with as they are needed for other calculations. Additionally this way
  // is technically more precise as well.

  const vec3 hitPosition = interpolateHitAttribute(worldPositions, bary);
  // Note: Much like normals and texture coordinates hit positions may be invalid and could be sanitized here after interpolation, but there is not as much reason to.
  // Invalid positions will simply move a vertex far away or "delete" it entirely depending on how the hardware handles it which while will result in obvious visual
  // glitches is pretty much the same as would happen if the value was sanitized to 0. As such there's not much improvement to the overall correctness of Remix to do so
  // and it is better to avoid doing so to save performance. If invalid positions are causing invalid values to propagate into other buffers in the future though
  // then sanitization may have to be done.

  surfaceInteraction.position = hitPosition;

  // Update the position error because it might be larger in world space than in object space
  surfaceInteraction.positionError = max(surfaceInteraction.positionError, calculatePositionError(hitPosition));

  // Compute various normals

  const vec3 ab = worldPositions[1] - worldPositions[0];
  const vec3 ac = worldPositions[2] - worldPositions[0];
  const vec3 worldTriangleVector = cross(ab, ac);

  // Note: Fall back to an arbitrary vector for degenerate triangles where a triangle normal cannot be derived. Note this
  // will not produce a valid normal for cases where the positional data itself is NaN/Inf, but these cases likely indicate
  // corruption in the original data to begin with.
  const vec3 worldTriangleNormal = safeNormalize(worldTriangleVector, vec3(0.0f, 0.0f, 1.0f));
  // Note: Ideally cheaper than using length to get the magnitude of the cross product's result (no sqrt required).
  const float worldTwoTriangleArea = dot(worldTriangleVector, worldTriangleNormal);
  surfaceInteraction.triangleArea = worldTwoTriangleArea * 0.5;

  // Note: fp16 conversion done after area calculation so the fp32 normal can be used
  const f16vec3 triangleNormal = f16vec3(worldTriangleNormal);
  const bool triangleNormalSameDirection = dot(triangleNormal, rayInteraction.viewDirection) >= float16_t(0.0);
  const f16vec3 flippedTriangleNormal = triangleNormalSameDirection ? triangleNormal : -triangleNormal;

  surfaceInteraction.triangleNormal = flippedTriangleNormal;

  if (surface.normalBufferIndex == BINDING_INDEX_INVALID)
  {
    surfaceInteraction.interpolatedNormal = surfaceInteraction.triangleNormal;
  }
  else
  {
    vec3 normals[3];
  
    for (uint i = 0; i < 3; i++)
    {
      const uint currentIndex = idx[i];
  
      const uint normalBufferIndex = surface.normalBufferIndex;
      const uint normalElementIndex = (currentIndex * uint(surface.normalStride) + surface.normalOffset) / 4;
  
      if (surface.normalsEncoded)
      {
        const uint encodedNormal = floatBitsToUint(BUFFER_ARRAY(geometries, normalBufferIndex, normalElementIndex));
        const vec3 decodedNormal = unsignedOctahedralToSphereDirection(vec2(
          unorm16ToF32(uint16_t(encodedNormal >> 0)),
          unorm16ToF32(uint16_t(encodedNormal >> 16))
        ));

        normals[i] = decodedNormal;
      }
      else
      {
        normals[i].x = BUFFER_ARRAY(geometries, normalBufferIndex, normalElementIndex + 0);
        normals[i].y = BUFFER_ARRAY(geometries, normalBufferIndex, normalElementIndex + 1);
        normals[i].z = BUFFER_ARRAY(geometries, normalBufferIndex, normalElementIndex + 2);
      }
    }

    // Note: Fall back to the triangle normal when an interpolated normal cannot be derived. Note this will not produce a
    // valid normal for cases where the positional data itself is NaN/Inf, but these cases likely indicate corruption in
    // the original data to begin with.
    const vec3 objectInterpolatedNormal = safeNormalize(interpolateHitAttribute(normals, bary), triangleNormal);
    // Note: This is done due to input data from source applications potentially containing NaNs/Infs and thus needing to be sanitized before being
    // used in Remix. This is done here rather than earlier when normals are read from the buffer to only sanitize once rather than for
    // each of the 3 vertex normals. Do note however that keeping this as close to the interpolation step as possible is important to avoid
    // hiding invalid values from other logic in Remix.
    const f16vec3 sanitizedObjectInterpolatedNormal = sanitize(objectInterpolatedNormal, triangleNormal);
  
    // Note: Second normalization required as vector may be scaled through a normal transformation
    const f16vec3 interpolatedNormal = f16vec3(normalize(mul(surface.normalObjectToWorld, sanitizedObjectInterpolatedNormal)));
    // Really the only reason to flip this normal is for double-sided geometry.  Do not flip based on view vector!
    const bool interpolatedNormalSameDirection = dot(interpolatedNormal, flippedTriangleNormal) >= float16_t(0.0);
    const f16vec3 flippedInterpolatedNormal = interpolatedNormalSameDirection ? interpolatedNormal : -interpolatedNormal;

    const f16vec3 bentInterpolatedNormal = getBentNormal(surfaceInteraction.triangleNormal, flippedInterpolatedNormal, ray.direction);

    surfaceInteraction.interpolatedNormal = bentInterpolatedNormal;
  }

  // Compute motion
  // Note: Ignore the motion if the caller needs previous positions, we don't know it.

  if (!surface.isStatic && !usePreviousPositions)
  {
    vec3 prevObjectPosition = interpolateHitAttribute(positions, bary);

    if (surface.previousPositionBufferIndex != BINDING_INDEX_INVALID)
    {
      vec3 prevPositions[3];

      for (uint i = 0; i < 3; i++)
      {
        const uint currentIndex = idx[i];

        const uint previousPositionBufferIndex = surface.previousPositionBufferIndex;
        const uint previousPositionElementIndex = (currentIndex * uint(surface.positionStride) + surface.positionOffset) / 4;

        prevPositions[i].x = BUFFER_ARRAY(geometries, previousPositionBufferIndex, previousPositionElementIndex + 0);
        prevPositions[i].y = BUFFER_ARRAY(geometries, previousPositionBufferIndex, previousPositionElementIndex + 1);
        prevPositions[i].z = BUFFER_ARRAY(geometries, previousPositionBufferIndex, previousPositionElementIndex + 2);
      }

      prevObjectPosition = interpolateHitAttribute(prevPositions, bary);
    }

    const vec3 prevPosition = mul(surface.prevObjectToWorld, vec4(prevObjectPosition, 1.0f));

    surfaceInteraction.motion = prevPosition - hitPosition;
  }
  else
  {
    surfaceInteraction.motion = vec3(0.0);
  }

  // Compute texture coordinates

  if (surface.texcoordBufferIndex != BINDING_INDEX_INVALID || surface.texcoordGenerationMode != uint(TexGenMode::None))
  {
    // Note: This can be potentially extended to vec3 or vec4 if we ever want to support more than 2 texture transform elements
    // (potentially useful for say cubemap sampling, but Remix has little use to actually render cubemaps properly outside
    // of say sky capturing since ray traced reflections will replace most cubemap effects).
    vec2 texcoords[3];

    for (uint i = 0; i < 3; i++)
    {
      vec4 rawTextureCoordinate;

      if (surface.texcoordGenerationMode == uint(TexGenMode::ViewPositions) ||
          // For now, calculate texcoords for the first cascade. The texcoords for an appropriate cascade will get adjusted based on the interpolated texcoord later
          surface.texcoordGenerationMode == uint(TexGenMode::CascadedViewPositions))
      {
        const float4 viewPos = mul(cb.camera.worldToView, float4(worldPositions[i], 1.f));

        rawTextureCoordinate = viewPos;
      }
      else if (surface.texcoordGenerationMode == uint(TexGenMode::ViewNormals)) 
      {
        const uint currentIndex = idx[i];
        const uint normalBufferIndex = surface.normalBufferIndex;
        const uint normalElementIndex = (currentIndex * uint(surface.normalStride) + surface.normalOffset) / 4;

        float3 normal;
        normal.x = BUFFER_ARRAY(geometries, normalBufferIndex, normalElementIndex + 0);
        normal.y = BUFFER_ARRAY(geometries, normalBufferIndex, normalElementIndex + 1);
        normal.z = BUFFER_ARRAY(geometries, normalBufferIndex, normalElementIndex + 2);

        normal = normalize(mul(surface.normalObjectToWorld, normal));

        const float4 viewPos = mul(cb.camera.worldToView, float4(normal, 0.f));

        // Todo: Use the full vec4 viewPos here if rawTextureCoordinate is ever expanded to be a vec4 (right
        // now the other 2 components will never matter in our current implementation).
        rawTextureCoordinate = viewPos;
      }
      else
      {
        const uint currentIndex = idx[i];
        uint texcoordBufferIndex = surface.texcoordBufferIndex;
        const uint texcoordElementIndex = (currentIndex * uint(surface.texcoordStride) + surface.texcoordOffset) / 4;

        const vec2 loadedTextureCoordinate = vec2(
          BUFFER_ARRAY(geometries, texcoordBufferIndex, texcoordElementIndex + 0),
          BUFFER_ARRAY(geometries, texcoordBufferIndex, texcoordElementIndex + 1)
        );

        // Todo: This will likely need to load more than a vec2 of texture coordinates too if we ever support anything more complex.
        // A value of 1 is added to every component beyond what is loaded, though it really should be a value of 0 up to the texture
        // transform element count and 1 past that I think, check DXVK's d3d9_fixed_function.cpp for more info.
        rawTextureCoordinate = float4(loadedTextureCoordinate, 1.0f, 1.0f);
      }

      const vec2 transformedTextureCoordinate = mul(surface.textureTransform, rawTextureCoordinate);

      // Todo: Perspective division here on the proper component (as specified by the number of elements the transform is expected to output)
      // when projective texture transforms are enabled.

      // Todo: Use the full vec4 here if transformedTextureCoordinate is ever expanded to be a vec4 (right
      // now the other 2 components will never matter in our current implementation, and this covers the
      // 1 component case as sampling from a 1D texture will just ignore the second coordinate, though not sure
      // what would happen with a 2D texture given only a 1D transform result...).
      texcoords[i] = transformedTextureCoordinate;
    }

    const vec2 interpolatedTextureCoordinates = interpolateHitAttribute(texcoords, bary);
    // Note: This is done due to input data from source applications potentially containing NaNs/Infs and thus needing to be sanitized before being
    // used in Remix. This is done here rather than earlier when texture coordinates are read from the buffer to only sanitize once rather than for
    // each of the 3 texture coordinate values. Do note however that keeping this as close to the interpolation step as possible is important to avoid
    // hiding invalid values from other logic in Remix.
    const vec2 sanitizedInterpolatedTextureCoordinates = sanitize(interpolatedTextureCoordinates, vec2(0.0f, 0.0f));

    surfaceInteraction.textureCoordinates = sanitizedInterpolatedTextureCoordinates;

    if (GenerateTangents)
    {
      // Note: World positions used here, the original PBRT usage uses model space vertex positions since it calculates the
      // TBN  in local space, but since we generate the TBN frame in world space this is more applicable. Additionally
      // it removes the need to keep the object space positions around which should ideally reduce register pressure.
      genTangSpace(
      texcoords, worldPositions, surfaceInteraction.interpolatedNormal,
      surfaceInteraction.interpolatedTangent, surfaceInteraction.interpolatedBitangent, surfaceInteraction.rawTangent, surfaceInteraction.rawBitangent);
    
      // Derive triangle TBN based on interpolated TBN. This works in all cases tested,
      // and should be much cheaper than calling genTangSpace again.
      f16vec4 interpolatedToTriangle = quaternionCreateOrientation(surfaceInteraction.interpolatedNormal, surfaceInteraction.triangleNormal);
      surfaceInteraction.triangleTangent = quaternionTransformVector(interpolatedToTriangle, surfaceInteraction.interpolatedTangent);
      surfaceInteraction.triangleBitangent = quaternionTransformVector(interpolatedToTriangle, surfaceInteraction.interpolatedBitangent);
    }
    
    // Convert texcoords from the 1st cascade to a corresponding cascade in a combined tiled cascades texture space
    if (surface.texcoordGenerationMode == uint(TexGenMode::CascadedViewPositions))
    {
      uint cascadeLevel = 0;

      // Calculate the texcoords for cascade maps with more than one cascade.
      // Texcoords for the first cascade are already correct if there's only a single cascade in the map
      if (cb.terrainArgs.maxCascadeLevel > 0) 
      {
        // For surfaces with displacement, we need to ensure the final hit point is within a cascade level.
        // To do this, calculate the furthest texcoord that displacement could return, and use a cascade level that includes that point.
        const f16mat3 worldToTangent = f16mat3(surfaceInteraction.interpolatedTangent, surfaceInteraction.interpolatedBitangent, surfaceInteraction.interpolatedNormal);
        const f16vec3 viewDirTangentSpace = normalize(mul(worldToTangent, rayInteraction.viewDirection));
        // viewDirection is hitPos to camera, so invert it before converting to a texcoord offset.
        const vec2 maxPossiblePomOffset = viewDirTangentSpace.xy * (-1.f * cb.terrainArgs.displaceIn / viewDirTangentSpace.z);

        const vec2 textureCenterOffset = texcoordToOffsetFromTextureCenter(surfaceInteraction.textureCoordinates + maxPossiblePomOffset);
        const float maxTextureCenterOffset = length(textureCenterOffset);

        // Calculate a cascade level if sampling outside the first cascade
        if (maxTextureCenterOffset >= 0.5)
        {
          // Convert the offset from <0, 0.5> to <0, 1> of the first cascade 
          const float normalizedTextureCenterOffset = maxTextureCenterOffset * 2;

          // Calculate the cascade level starting from cascade level 1
          cascadeLevel = min(ceil(log2(normalizedTextureCenterOffset)), cb.terrainArgs.maxCascadeLevel);
        }
        // Note: This is safe to do after the Tangent space generation because it only translates and scales.  It does not change the normalized derivatives.
        convert1stCascadeTexCoordsToTargetCascadeLevel(cascadeLevel, surfaceInteraction.textureCoordinates, texcoords);
      }

#if defined(RAY_TRACING_PRIMARY_RAY)
      if (cb.debugView == DEBUG_VIEW_CASCADE_LEVEL)
      {
        storeInDebugView(getDispatchRaysIndex().xy, cascadeLevel);
      }
      else if (cb.debugView == DEBUG_VIEW_IS_BAKED_TERRAIN)
      {
        storeInDebugView(getDispatchRaysIndex().xy, 1);
      }
#endif
    }
    
    // Compute texture gradients
    // Note: This is done here as it depends on the triangle normal and texture coordinates being calculated first

    // Note: Non-flipped world space triangle normal passed in to be consistent with the calculations done internally (rather
    // than worrying about if the flipped vector could break it)
    if (footprintMode != kFootprintFromTextureCoordDiff)
    {
      const vec3 positionOffset = surfaceInteraction.position - ray.origin;
      const f16vec3 direction = footprintMode == kFootprintFromRayDirection ? ray.direction : normalize(positionOffset);
      const float16_t coneRadius = footprintMode == kFootprintFromRayDirection ? rayInteraction.coneRadius : rayInteraction.coneRadius + length(positionOffset) * ray.spreadAngle;

      computeAnisotropicEllipseAxes(
        hitPosition, triangleNormal, worldTwoTriangleArea, direction,
        coneRadius, worldPositions, texcoords, surfaceInteraction.textureCoordinates,
        surfaceInteraction.textureGradientX, surfaceInteraction.textureGradientY);

      if (footprintMode == kFootprintFromRayOriginClamped)
      {
        vec2 dUV1 = texcoords[1] - texcoords[0];
        vec2 dUV2 = texcoords[2] - texcoords[0];
        float dUVCross = abs(dUV1.x * dUV2.y - dUV2.x * dUV1.y);
        float radius = dUVCross / (length(dUV1) + length(dUV2) + length(dUV2 - dUV1));
        float maxFootprint = radius * 1.5;
        surfaceInteraction.textureGradientX *= min(1.0, maxFootprint / length(surfaceInteraction.textureGradientX));
        surfaceInteraction.textureGradientY *= min(1.0, maxFootprint / length(surfaceInteraction.textureGradientY));
      }
    }
    else
    {
      surfaceInteraction.textureGradientX = (texcoords[1] - texcoords[0]) / 3.0f;
      surfaceInteraction.textureGradientY = (texcoords[2] - texcoords[0]) / 3.0f;
    }
  }
  else
  {
    surfaceInteraction.textureGradientX = 0.f;
    surfaceInteraction.textureGradientY = 0.f;
    surfaceInteraction.textureCoordinates = vec2(0.f);

    // Create dummy tangent basis thats reasonable WRT normal
    calcOrthonormalBasis(
      surfaceInteraction.interpolatedNormal,
      surfaceInteraction.interpolatedTangent,
      surfaceInteraction.interpolatedBitangent);

    calcOrthonormalBasis(
      surfaceInteraction.triangleNormal,
      surfaceInteraction.triangleTangent,
      surfaceInteraction.triangleBitangent);
  }

  // Adjust texture coordinates and gradients for animated sprite sheet logic

  if (!surface.skipSurfaceInteractionSpritesheetAdjustment)
  {
    calcSpriteSheetAdjustment(
      surfaceInteraction.textureCoordinates,
      surfaceInteraction.textureGradientX,
      surfaceInteraction.textureGradientY,
      cb.timeSinceStartSeconds,
      surface.spriteSheetRows,
      surface.spriteSheetCols,
      surface.spriteSheetFPS);
  }

  // Baked terrain is the only surface using cascaded view positions, so key off of that. 
  const bool isBakedTerrain = surface.texcoordGenerationMode == uint(TexGenMode::CascadedViewPositions);

  // Compute vertex colors

  if (surface.color0BufferIndex != BINDING_INDEX_INVALID &&
     // Baked terrain has vertex colors already baked in, so default to neutral vertex color of 1.
     // They won't get reapplied later anyway
     !isBakedTerrain)
  {
    f16vec4 color[3];

    for (uint i = 0; i < 3; i++)
    {
      const uint currentIndex = idx[i];

      const uint color0BufferIndex = surface.color0BufferIndex;
      const uint color0ElementIndex = (currentIndex * uint(surface.color0Stride) + surface.color0Offset) / 4;

      // VK_FORMAT_B8G8R8A8_UNORM
      const uint colorBits = floatBitsToUint(BUFFER_ARRAY(geometries, color0BufferIndex, color0ElementIndex));

      color[i].x = unorm8ToF16(uint8_t(colorBits >> 16));
      color[i].y = unorm8ToF16(uint8_t(colorBits >> 8));
      color[i].z = unorm8ToF16(uint8_t(colorBits));
      color[i].w = unorm8ToF16(uint8_t(colorBits >> 24));
    }

    surfaceInteraction.vertexColor = interpolateHitAttribute(color, bary);
  }
  else
  {
    surfaceInteraction.vertexColor = f16vec4(1.0, 1.0, 1.0, 1.0);
  }

  return surfaceInteraction;
}

// Todo: Surface interaction construction function from sampled position

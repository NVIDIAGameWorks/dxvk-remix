/*
* Copyright (c) 2023, NVIDIA CORPORATION. All rights reserved.
*
* Permission is hereby granted, free of charge, to any person obtaining a
* copy of this software and associated documentation files (the "Software"),
* to deal in the Software without restriction, including without limitation
* the rights to use, copy, modify, merge, publish, distribute, sublicense,
* and/or sell copies of the Software, and to permit persons to whom the
* Software is furnished to do so, subject to the following conditions:
*
* The above copyright notice and this permission notice shall be included in
* all copies or substantial portions of the Software.
*
* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
* IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
* FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
* THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
* LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
* FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
* DEALINGS IN THE SOFTWARE.
*/
#pragma once

#include "opaque_surface_material_blending.slangh"

// Opaque Surface Material Interaction Constants

// Note: Threshold value to use for considering the albedo zero or non-zero for some calculations.
static const f16vec3 albedoThreshold = f16vec3(1.0h / 256.0h);
// Note: Threshold value to use for considering the base reflectivity zero or non-zero for some calculations.
static const f16vec3 baseReflectivityThreshold = f16vec3(1.0h / 256.0h);
// Note: Threshold value to use for considering the roughness (not the perceptual roughness) zero or non-zero for some calculations.
// Must be greater than materialMinimumRoughness in the BRDF helpers as all roughnesses will be clamped to at minimum this value.
static const float16_t roughnessThreshold = float16_t(0.001h);

// Opaque Surface Material Interaction Helper Functions

#ifdef OPAQUE_MATERIAL_USE_POM
// Parallax Occlusion Mapping Helper Functions
// Define a `box` as a region in tangent space that corresponds to a pixel in a mipmap level, with min_z = 0 and max_z equal to the max height in that region.

// get the smaller corner of the box that contains 'pos'
float2 pomGetBoxCorner(float2 pos, float2 boxSize)
{
  return floor(pos / boxSize) * boxSize;
}

// size in tangent space of a box at a given mip level
float2 pomGetBoxSize(uint level, uint2 fullBoxSize)
{
  uint2 levelSize =  max(fullBoxSize >> level, 1u);
  return 1.f / levelSize;
}

float pomGetBoxHeight(Texture2D texture, SamplerState sampler, float2 boxCenter, uint level) 
{
  return texture.SampleLevel(sampler, boxCenter, level - cb.totalMipBias).r;
}

float4 pomGetPatchCorners(Texture2D texture, SamplerState sampler, float2 boxCenter, float2 boxStep, float height, uint level)
{
  // Read the 3x3 patch around the current box
  const float box00 = pomGetBoxHeight(texture, sampler, boxCenter + boxStep * float2(-1.f, -1.f), level);
  const float box01 = pomGetBoxHeight(texture, sampler, boxCenter + boxStep * float2(-1.f,  0.f), level);
  const float box02 = pomGetBoxHeight(texture, sampler, boxCenter + boxStep * float2(-1.f,  1.f), level);
  const float box10 = pomGetBoxHeight(texture, sampler, boxCenter + boxStep * float2( 0.f, -1.f), level);
  // const float box11 = height;
  const float box12 = pomGetBoxHeight(texture, sampler, boxCenter + boxStep * float2( 0.f,  1.f), level);
  const float box20 = pomGetBoxHeight(texture, sampler, boxCenter + boxStep * float2( 1.f, -1.f), level);
  const float box21 = pomGetBoxHeight(texture, sampler, boxCenter + boxStep * float2( 1.f,  0.f), level);
  const float box22 = pomGetBoxHeight(texture, sampler, boxCenter + boxStep * float2( 1.f,  1.f), level);

  // Set each corner of the box to the min of the surrounding boxes.  This is needed because the mip values are maximum heights,
  // and we want each box to share corners.
  // returns a float4 representing the height of each corner, as 00, 01, 10, 11.
  return float4(
    min(min(box00, box01), min(box10, height)),
    min(min(box01, box02), min(height, box12)),
    min(min(box10, height), min(box20, box21)),
    min(min(height, box12), min(box21, box22))
  );
}

// cast a ray in tangent space.  return an intersection point in tangent point (or an exit point if z > 1.0f)
float3 pomTraceRay(Texture2D texture, SamplerState sampler, float3 origin, float3 direction, float2 textureGradientX, float2 textureGradientY, inout uint iterations)
{
  // Potential future improvements for outwards rays:
  // 1) calculate starting height the same way the box intersection code does instead of just sampling at a pixel.
  // 2) allow rays to escape the surface, only do intersection on entering the surface.
  uint fullWidth, fullHeight, numMipLevels = 0;
  texture.GetDimensions(0, fullWidth, fullHeight, numMipLevels);
  const uint2 fullBoxSize = uint2(fullWidth, fullHeight);
  const bool isOutwardsRay = direction.z > 0.f;
  const float2 ddx_tex = textureGradientX * fullBoxSize;
  const float2 ddy_tex = textureGradientY * fullBoxSize;
  const float dd_max_sq = max(dot(ddx_tex, ddx_tex), dot(ddy_tex, ddy_tex));
  uint minMipLevel = max(0, min(numMipLevels, log2(sqrt(dd_max_sq)) + cb.totalMipBias));

  // Starting halfway down the quadtree seems to generally lead to fewer iterations to resolve, especially for heights close to 1.
  // Outwards rays start at 0, since they will just descend to 0 if they start anywhere else.
  int level = isOutwardsRay ? 0 : max((numMipLevels - 1) / 2, minMipLevel);
  float3 curPos = origin;

  const float2 forwardStep = float2(direction.x >= 0.0f ? 1.f : -1.f, direction.y >= 0.0f ? 1.f : -1.f);
  const float2 forwardHalfStep = forwardStep * 0.5f;
  iterations = 0;
  level = level;
  float prevHeight = 1.f;
  while (level >= minMipLevel && iterations < cb.pomMaxIterations && (!isOutwardsRay || curPos.z <= 1.f))
  {
    iterations++;
    const float2 boxSize = pomGetBoxSize(level, fullBoxSize);
    const float2 boxCenter = pomGetBoxCorner(curPos.xy, boxSize) + 0.5f * boxSize;
    const float height = pomGetBoxHeight(texture, sampler, boxCenter, level);
    if (level != minMipLevel && curPos.z <=  height) {
      // For mip levels above the minimum, if the curPos is below the max height of the box, just descend a level.
      level = level - 1;
      continue;
    }
    // The axis aligned planes where the ray will exit the box.
    const float2 boxFarCorner = boxCenter + forwardHalfStep * boxSize;

    // The distance to intersect with the x, y, and z planes.
    // origin.x + distance.x * m = bounds.x
    // m = (bounds.x - origin.x) / distance.x
    const float3 intersectDist = (float3(boxFarCorner, height) - origin) / direction;
    const float boundsIntersect = min(intersectDist.x, intersectDist.y);

    // The actual point where the ray exits the box.
    const float3 boxExit = origin + boundsIntersect * direction;

    if (!isOutwardsRay && intersectDist.z <= boundsIntersect)
    {
      // Hit the top of a box with an Inward ray.  
      if (level == 0)
      {
        // When a single texel stretches across multiple on screen pixels, we intersect against a virtual mesh
        // constructed from the height map.
        // The virtual mesh needs to be water tight, and needs to be fully contained by the boxes of each mip
        // level - meaning the max height in a pixel cannot be higher than the actual value of the pixel.  We also
        // want this surface to be smooth, rather than being a series of boxes. Constructing this vitual surface
        // as a quad where each vertex is at a corner of the box, and has a height equal to the minimum of the four
        // surrounding pixels will meet those requirements, but does cut off a single pixel spike, and makes a
        // single pixel pit have a flat bottom.

        // NOTE: I tried improving this algorithm by colliding against a series of 4 triangles, where each triangle 
        // is made of the center pixel value combined with 2 box corners from the above approach.  This unfortunately
        // causes smooth slops to turn jagged. It may be an improvement to use that approach only when the current
        // pixel is the largest or smallest of all the neighbors, but that seemed too complex to be worth pursuing.
        
        // Calculate the point where  the ray entered this box:
        const float2 boxNearCorner = boxCenter - forwardHalfStep * boxSize;
        const float2 boxEntranceDist = (boxNearCorner - origin.xy) / direction.xy;
        const float3 boxEntrance = origin + max(0.0f, max(boxEntranceDist.x, boxEntranceDist.y)) * direction;

        const float2 forwardBoxStep = boxSize * forwardStep;
        const float4 corners = pomGetPatchCorners(texture, sampler, boxCenter, forwardBoxStep, height, minMipLevel);
        iterations += 8; // 8 texture lookups for the patch corners, count it as 8 iterations.

        // Normalize the entrance and exit coords to a 0-1 space for lerping.
        const float2 normalEntranceCoord = (boxEntrance.xy - boxNearCorner.xy) / forwardBoxStep;
        const float2 normalExitCoord = (boxExit.xy - boxNearCorner.xy) / forwardBoxStep;

        // We expect one coord of the normalized entrance and exit coords to be 0.  Lerping like this becomes a linear interpolation
        // across the two corners the coord sits between.
        const float entranceHeight = lerp(lerp(corners[0], corners[2], normalEntranceCoord.x), lerp(corners[1], corners[3], normalEntranceCoord.x), normalEntranceCoord.y);
        const float exitHeight = lerp(corners[2], lerp(corners[1], corners[3], normalExitCoord.x), normalExitCoord.y);

        // intersect the ray against that line segment. (2d line intersection works here)
        const float frac = (boxEntrance.z - entranceHeight) / ((exitHeight - entranceHeight) - (boxExit.z - boxEntrance.z));
        const float3 interceptPos = boxEntrance + (boxExit - boxEntrance) * frac;
        
        if (entranceHeight > boxEntrance.z || (frac <= 1 && interceptPos.z <= height && frac >= 0)) {
          // `entranceHeight > boxEntrance.z` return if ray is already under the surface at the near side of the box.
          // `frac <= 1` reject all intersections past the far side of the box.
          // `interceptPos.z <= maxGeoHeight` reject intersections that happen above the highest point of the surface in the box.
          // `frac > 0` reject intersections that happened before the near side of the box.
          return interceptPos;
        }
        // didn't hit the virtual surface, move to next box
      }
      else if (level == minMipLevel)
      {
        // Hit the top of the box at the min mip level, but far enough away that the min mip level is > 0.
        // Use a very simple linear interpolation between prev cell height at entrance, and current cell height at exit to get a collision.
        const float frac = (curPos.z - prevHeight) / ((height - prevHeight) - (boxExit.z - curPos.z));
        return curPos + (boxExit - curPos) * frac;
      }
      else if (level > minMipLevel)
      {
        // Proceed to z intersection and reduce mip.
        curPos = origin + intersectDist.z * direction;
        level = level - 1;
        continue;
      }
    } 
    // intersected with sides of box
    int nextLevel = min( numMipLevels - 1, level + 1);
    // (note, ideally we would just use something like std::nextafterf on boundsIntersect)
    const float3 nextPos = boxExit + direction * min(boxSize.x, boxSize.y) * 0.01f;

    // Maybe don't move up level
    float2 nextBoxSize = pomGetBoxSize(nextLevel, fullBoxSize);
    if (any(pomGetBoxCorner(curPos.xy, nextBoxSize) != pomGetBoxCorner(nextPos.xy, nextBoxSize)))
    {
      level = nextLevel;
    }
    curPos = nextPos;
    prevHeight = height;
  }

  // Outwards rays can go past the top of the POM surface, so limit it to there.
  if (curPos.z > 1) {
    float distToOne = (1.0f - origin.z) / direction.z;
    return origin + distToOne * direction;
  }
  return curPos;
}


float pomSampleHeight(uint16_t idx, uint16_t samplerIndex, float2 texcoord)
{
  return 1.0f - textures[nonuniformEXT(uint(idx))].SampleLevel(samplers[nonuniformEXT(uint(samplerIndex))], texcoord, 0).r;
}

float2 pomGetStep(float3 direction, float layerSize, float displaceIn)
{
  // convert tangent space direction to texcoord
  return direction.xy / direction.z * displaceIn * layerSize;
}

float pomGetNumSamples(float3 direction)
{
  const float minSamples = cb.pomMaxIterations / 4.f;
  const float maxSamples = cb.pomMaxIterations;

  // more samples when viewing from oblique angle
  return lerp(maxSamples, minSamples, abs(direction.z));
}

float3 pomCalculateTexcoord(
  OpaqueSurfaceMaterial opaqueSurfaceMaterial,
  SurfaceInteraction surfaceInteraction,
  float3 viewDir,
  inout uint iterations)
{
  if (cb.pomMode == DisplacementMode::RaymarchPOM) {
    float numLayers = pomGetNumSamples(viewDir);
    float layerSize = rcp(numLayers);
    float2 step = pomGetStep(viewDir, layerSize, opaqueSurfaceMaterial.displaceIn);

    float2 currTexcoord = surfaceInteraction.textureCoordinates;
    float currHeight = pomSampleHeight(opaqueSurfaceMaterial.heightTextureIndex, opaqueSurfaceMaterial.samplerIndex, currTexcoord);

    // raymarch to find intersection
    float currDepth = 0.0f, prevHeight = 0.0f;
    iterations = 0;
    while(currDepth < currHeight)
    {
      iterations++;
      currTexcoord -= step;
      prevHeight = currHeight;
      currHeight = pomSampleHeight(opaqueSurfaceMaterial.heightTextureIndex, opaqueSurfaceMaterial.samplerIndex, currTexcoord);
      currDepth += layerSize;
    }

    // interpolate last two samples to reduce sample aliasing
    float depthNminus1 = prevHeight - currDepth + layerSize;
    float depthN  = currHeight - currDepth;
    float weight = saturate(depthN / (depthN - depthNminus1));
    return float3(currTexcoord + lerp(0..xx, step, weight), currHeight);
  } else if (cb.pomMode == DisplacementMode::QuadtreePOM) {
    return pomTraceRay(
        textures[nonuniformEXT(uint(opaqueSurfaceMaterial.heightTextureIndex))],
        samplers[nonuniformEXT(uint(opaqueSurfaceMaterial.samplerIndex))],
        float3(surfaceInteraction.textureCoordinates, 1.0f),
        -float3(viewDir.xy, viewDir.z / opaqueSurfaceMaterial.displaceIn),
        surfaceInteraction.textureGradientX,
        surfaceInteraction.textureGradientY,
        iterations);
  }
  return float3(surfaceInteraction.textureCoordinates, 1.f);
}

float pomSampleVisibility(
    uint16_t heightTextureIdx,
    uint16_t samplerIndex,
    float2 texcoord,
    float3 rayDirection,
    float displaceIn)
{
  // NOTE: pomTraceRay could be used here, but testing found it was more expensive and had worse artifacts when
  // doing visibility testing.
  float2 currTexcoord = texcoord;
  float currHeight = pomSampleHeight(heightTextureIdx, samplerIndex, currTexcoord);
  float currDepth = currHeight;
  float numLayers = pomGetNumSamples(rayDirection);
  float layerSize = rcp(numLayers);
  float2 step = pomGetStep(rayDirection, layerSize, displaceIn);


  float visibility = 1.0f;
  while (currDepth > 0.0f)
  {
    currTexcoord += step;
    currHeight = pomSampleHeight(heightTextureIdx, samplerIndex, currTexcoord);
    currDepth -= layerSize;

    if(currHeight < currDepth)
    {
      visibility -= (currDepth - currHeight) / layerSize;
    }
  }

  return saturate(visibility);
}

float opaqueSurfaceMaterialInteractionCalcHeightThroughput(
  MinimalSurfaceInteraction minimalSurfaceInteraction,
  f16vec3 rayDirection,
  uint16_t heightTextureIdx,
  uint16_t samplerIndex,
  float2 texcoord,
  float displaceIn)
{
  // rebuild tangent space
  const f16mat3 worldToTangent = f16mat3(
    minimalSurfaceInteraction.triangleTangent,
    minimalSurfaceInteraction.triangleBitangent,
    minimalSurfaceInteraction.triangleNormal);
  const f16vec3 lightDirTangentSpace = normalize(mul(worldToTangent, rayDirection));
  return pomSampleVisibility(heightTextureIdx, samplerIndex, texcoord, lightDirTangentSpace, displaceIn);
}
#endif

SubsurfaceMaterialInteraction subsurfaceMaterialInteractionCreate(
  SubsurfaceMaterial subsurfaceMaterial,
  SurfaceInteraction surfaceInteraction,
  uint16_t samplerIndex)
{
  f16vec4 transmittanceColor;
  f16vec4 subsurfaceMeasurementDistance;
  f16vec4 subsurfaceSingleScatteringAlbedo;

  bool measurementDistanceLoaded = surfaceMaterialInteractionTextureReadHelper(subsurfaceMaterial.subsurfaceThicknessTextureIndex, samplerIndex, surfaceInteraction, subsurfaceMeasurementDistance);
  bool transmittanceColorLoaded = surfaceMaterialInteractionTextureReadHelper(subsurfaceMaterial.subsurfaceTransmittanceTextureIndex, samplerIndex, surfaceInteraction, transmittanceColor);
  bool singleScatteringAlbedoLoaded = surfaceMaterialInteractionTextureReadHelper(subsurfaceMaterial.subsurfaceSingleScatteringAlbedoTextureIndex, samplerIndex, surfaceInteraction, subsurfaceSingleScatteringAlbedo);

  SubsurfaceMaterialInteraction subsurfaceMaterialInteraction;

  if (measurementDistanceLoaded)
  {
    subsurfaceMaterialInteraction.measurementDistance = subsurfaceMeasurementDistance.r;
  }
  else
  {
    subsurfaceMaterialInteraction.measurementDistance = subsurfaceMaterial.measurementDistance;
  }

  // volumetricAttenuationCoefficient must be read behind measurementDistance, because if using sss textures, the volumetricAttenuationCoefficient need to be calculated base on measurementDistance
  if (transmittanceColorLoaded)
  {
    subsurfaceMaterialInteraction.packedTransmittanceColor = colorToR5G6B5(transmittanceColor.rgb);
  }
  else
  {
    subsurfaceMaterialInteraction.packedTransmittanceColor = colorToR5G6B5(evalBeerLambertAttenuation(subsurfaceMaterial.volumetricAttenuationCoefficient, subsurfaceMaterial.measurementDistance));
  }

  if (singleScatteringAlbedoLoaded)
  {
    subsurfaceMaterialInteraction.packedSingleScatteringAlbedo = colorToR5G6B5(subsurfaceSingleScatteringAlbedo.rgb);
  }
  else
  {
    subsurfaceMaterialInteraction.packedSingleScatteringAlbedo = colorToR5G6B5(subsurfaceMaterial.singleScatteringAlbedo);
  }

  subsurfaceMaterialInteraction.volumetricAnisotropy = f16ToSnorm8(subsurfaceMaterial.volumetricAnisotropy);

  return subsurfaceMaterialInteraction;
}

void storeColorOverlayedWithTextureResolutionCheckersInDebugView(vec3 colorValue, uint textureIndex, SurfaceInteraction surfaceInteraction)
{
  if (textureIndex != BINDING_INDEX_INVALID)
  {
    uint2 texDims;
    textures[nonuniformEXT(uint(textureIndex))].GetDimensions(texDims.x, texDims.y);

    colorValue = 
      tintColorValueWithTextureResolutionCheckers(
        colorValue,
        surfaceInteraction.textureCoordinates, 
        surfaceInteraction.textureGradientX * cb.upscaleFactor,
        surfaceInteraction.textureGradientY * cb.upscaleFactor,
        texDims,
        cb.debugKnob.x,
        cb.debugKnob.y);
    storeInDebugView(DispatchRaysIndex().xy, colorValue);
  }
}

// Opaque Surface Material Interaction Functions

OpaqueSurfaceMaterialInteraction opaqueSurfaceMaterialInteractionCreate(
  OpaqueSurfaceMaterial opaqueSurfaceMaterial,
  Surface surface,
  inout SurfaceInteraction surfaceInteraction,
  MinimalRayInteraction minimalRayInteraction)
{
  OpaqueSurfaceMaterialInteraction opaqueSurfaceMaterialInteraction;
  // Note: need initialize the flags explicitely to get rid of garbage data.
  opaqueSurfaceMaterialInteraction.flags = 0;

  // Create a tangent to world space matrix for future calculations

  const f16mat3 worldToTangent = f16mat3(surfaceInteraction.interpolatedTangent, surfaceInteraction.interpolatedBitangent, surfaceInteraction.interpolatedNormal);

  // Note: Does not represent if the thin film is enabled in all cases, such as if the thin film enable override is specified, merely concerned with if
  // it has been directly enabled by the material itself.
  const bool thinFilmEnabled = opaqueSurfaceMaterial.flags & OPAQUE_SURFACE_MATERIAL_FLAG_USE_THIN_FILM_LAYER;

  opaqueSurfaceMaterialInteraction.flags |= thinFilmEnabled ? OPAQUE_SURFACE_MATERIAL_INTERACTION_FLAG_USE_THIN_FILM_LAYER : 0;

#ifdef OPAQUE_MATERIAL_USE_POM
  if (cb.pomMode != DisplacementMode::Off && opaqueSurfaceMaterial.heightTextureIndex != BINDING_INDEX_INVALID && opaqueSurfaceMaterial.displaceIn > 0.0f)
  {
    const mat3 worldToTexture = inverse(transpose(mat3(surfaceInteraction.rawTangent, surfaceInteraction.rawBitangent, surfaceInteraction.interpolatedNormal)));
    // TextureGradient x might be along the same direction as the view ray?  make a debug view that shows the dot product between textureGradient.x and viewDirTangentSpace?

    f16vec3 viewDirTextureSpace = normalize(mul(worldToTexture, minimalRayInteraction.viewDirection));
    // Note: -1.f * TextureGradientX has the same x,y direction as viewDirTextureSpace, but calculating the correct z value is non-obvious.
    // Could potentially remove the need for the worldToTexture transform if a faster way to calculate that z value is found.

    uint iterations = 0; // unused
    surfaceInteraction.textureCoordinates = pomCalculateTexcoord(
        opaqueSurfaceMaterial,
        surfaceInteraction,
        viewDirTextureSpace,
        iterations).xy;
    opaqueSurfaceMaterialInteraction.flags |= opaqueSurfaceMaterial.heightTextureIndex != BINDING_INDEX_INVALID ? OPAQUE_SURFACE_MATERIAL_INTERACTION_FLAG_HAS_HEIGHT_TEXTURE : 0;
  }
#endif

  // Sample from each Opaque Surface Material texture

  f16vec4 albedoOpacitySample;
  f16vec4 normalSample;
  f16vec4 secondNormalSample;
  f16vec4 tangentSample;
  f16vec4 roughnessSample;
  f16vec4 metallicSample;
  f16vec4 emissiveColorSample;

  const bool albedoOpacityLoaded = surfaceMaterialInteractionTextureReadHelper(opaqueSurfaceMaterial.albedoOpacityTextureIndex, opaqueSurfaceMaterial.samplerIndex, surfaceInteraction, albedoOpacitySample);
  const bool normalLoaded = surfaceMaterialInteractionTextureReadHelper(opaqueSurfaceMaterial.normalTextureIndex, opaqueSurfaceMaterial.samplerIndex, surfaceInteraction, normalSample);

  bool secondNormalLoaded = false;
  if (cb.opaqueMaterialArgs.layeredWaterNormalEnable && surface.isAnimatedWater)
  {
    // take a second sample from a higher LOD using a modified texture xform
    const vec2 motionScale = vec2(cb.opaqueMaterialArgs.layeredWaterNormalMotionX, cb.opaqueMaterialArgs.layeredWaterNormalMotionY) * cb.opaqueMaterialArgs.layeredWaterNormalMotionScale;
    const float lodBias = cb.opaqueMaterialArgs.layeredWaterNormalLodBias;

    mat4x2 xform = surface.textureTransform;
    xform[0][2] *= motionScale.x;
    xform[1][2] *= motionScale.y;

    vec2 savedCoordinates = surfaceInteraction.textureCoordinates;
    surfaceInteraction.textureCoordinates = mul(xform, float4(surfaceInteraction.textureCoordinates, 0.f, 1.f)).xy;
    secondNormalLoaded = surfaceMaterialInteractionTextureReadHelper(opaqueSurfaceMaterial.normalTextureIndex, opaqueSurfaceMaterial.samplerIndex, surfaceInteraction, secondNormalSample, lodBias);
    surfaceInteraction.textureCoordinates = savedCoordinates;
  }

  const bool tangentLoaded = surfaceMaterialInteractionTextureReadHelper(opaqueSurfaceMaterial.tangentTextureIndex, opaqueSurfaceMaterial.samplerIndex, surfaceInteraction, tangentSample);
  const bool roughnessLoaded = surfaceMaterialInteractionTextureReadHelper(opaqueSurfaceMaterial.roughnessTextureIndex, opaqueSurfaceMaterial.samplerIndex, surfaceInteraction, roughnessSample);
  const bool metallicLoaded = surfaceMaterialInteractionTextureReadHelper(opaqueSurfaceMaterial.metallicTextureIndex, opaqueSurfaceMaterial.samplerIndex, surfaceInteraction, metallicSample);
  const bool emissiveColorLoaded = surfaceMaterialInteractionTextureReadHelper(opaqueSurfaceMaterial.emissiveColorTextureIndex, opaqueSurfaceMaterial.samplerIndex, surfaceInteraction, emissiveColorSample);

  // Load Albedo/Opacity

  f16vec3 albedo = opaqueSurfaceMaterial.albedoOpacityConstant.rgb;
  float16_t opacity = opaqueSurfaceMaterial.albedoOpacityConstant.a;
  float16_t emissiveBlendOverrideInfluence = float16_t(0.0f);
  float16_t thinFilmThickness = float16_t(0.0f);

  // Baked terrain is the only surface using cascaded view positions, so key off of that
  const bool isBakedTerrain = surface.texcoordGenerationMode == uint(TexGenMode::CascadedViewPositions);

  // Texture operations have already been applied during terrain baking, so skip them for baked terrain surfaces
  const bool applyTextureOperations = !isBakedTerrain;

  // Note: Set thin film thickness constant fallback only if the thin film is enabled as a non-zero value here is responsible for indicating
  // if the thin film is in use by later code.
  if (thinFilmEnabled)
  {
    thinFilmThickness = opaqueSurfaceMaterial.thinFilmThicknessConstant;
  }

  if (albedoOpacityLoaded)
  {
    albedo = albedoOpacitySample.rgb;

    // Note: Thin film thickness and opacity deriving their values from the alpha channel are mutually exclusive, set the appropriate
    // one based on the specified flags, and set the opposing variable to a default value (the "default" value must match how the material is decoded from the
    // GBuffer as well). Ideally we'd want to simply fall back on the existing opacity/thin film thickness constants instead, but we currently do not have a
    // way of encoding these values in the GBuffer, so a code constant must be used instead. Finally, thinFilmEnabled does not need to be checked here as the
    // alpha as thin film thickness flag is only set on the CPU if the use thin film flag is true.
    // Also, the alpha channel of the texture should always be linear even if it is using a sRGB encoding (as the alpha channel in such encodings remains linear),
    // so no special compensation has to be done here (unlike the albedo which may need to have software gamma correction skipped when reading from sRGB textures).
    if (opaqueSurfaceMaterial.flags & OPAQUE_SURFACE_MATERIAL_FLAG_ALPHA_IS_THIN_FILM_THICKNESS)
    {
      thinFilmThickness = albedoOpacitySample.a;
      opacity = float16_t(1.0f);
    }
    else
    {
      opacity = albedoOpacitySample.a;
      thinFilmThickness = float16_t(0.0f);
    }
  }

#if defined(RAY_TRACING_PRIMARY_RAY) && defined(RAY_PIPELINE)
  if (cb.debugView == DEBUG_VIEW_RAW_ALBEDO) 
  {
    storeInDebugView(DispatchRaysIndex().xy, albedo.xyz);
  }

  if (cb.debugView == DEBUG_VIEW_OPAQUE_RAW_ALBEDO_RESOLUTION_CHECKERS) 
  {
    storeColorOverlayedWithTextureResolutionCheckersInDebugView(albedo.xyz, opaqueSurfaceMaterial.albedoOpacityTextureIndex, surfaceInteraction);
  } 
#endif

  f16vec4 tFactor = 0.h;

  // WAR for REMIX-1573: texture ops for opacity should happen during baking and be skipped here for baked terrain,
  // but right now the opacity is not 1 in the baked texture where it is expected to be and thus texture ops
  // are required to blend the layer contributions properly 
#if 0
  if (applyTextureOperations) 
#endif
  {
    // Adjust opacity via texture operations.
    // Fixed function texture stage state for alpha channel

    float16_t textureAlphaArg1, textureAlphaArg2;

    // Note: Custom decoding done here rather than using our usual unorm to f16 decoding functions to match encoding
    // based on D3D9's texture factor encoding for a more exact representation.
    tFactor.a = float16_t((surface.tFactor >> 24) & 0xff) / 255.0h;
    tFactor.r = float16_t((surface.tFactor >> 16) & 0xff) / 255.0h;
    tFactor.g = float16_t((surface.tFactor >> 8)  & 0xff) / 255.0h;
    tFactor.b = float16_t((surface.tFactor)       & 0xff) / 255.0h;

    chooseTextureArgument(textureAlphaArg1, surface.textureAlphaArg1Source, opacity, surfaceInteraction.vertexColor.a, tFactor.a, opacity);
    chooseTextureArgument(textureAlphaArg2, surface.textureAlphaArg2Source, opacity, surfaceInteraction.vertexColor.a, tFactor.a, float16_t(1.0h));
    chooseTextureOperationAlpha(opacity, surface.textureAlphaOperation, textureAlphaArg1, textureAlphaArg2);
  
    calcOpaqueSurfaceMaterialOpacity(
      albedo, opacity, surface, opacity, emissiveBlendOverrideInfluence);
  }

  if (opaqueSurfaceMaterial.flags & OPAQUE_SURFACE_MATERIAL_FLAG_IGNORE_ALPHA_CHANNEL)
  {
      opacity = 1.h;
  }

  // Note: Gamma correct albedo input (be it from a constant or a texture). Currently assuming all textures are not using sRGB formats which
  // automatically do this conversion.
  // This conversion is done *after* calcOpaqueSurfaceMaterialOpacity to correctly apply double multiplicative blending.
  // Todo: Disable this for when a sRGB texture is the source of the albedo.
  albedo = gammaToLinear(albedo);

  // Apply vertex color via texture operations
  if (applyTextureOperations)
  {
    // "Normalize" vertex color to remove lighting contribution in different vertices.
    // We assume the diffuse term contributes most lighting. Therefore, vertex color = diffuseColor * (N*L).
    // By dividing the vertex color by its largest component, the result is irrelavant to N*L, but proportional to the 
    // original diffuse color, which is more desired.
    // In practice, we add an adjustable blending factor to avoid extreme cases.
    surfaceInteraction.vertexColor.rgb = max(surfaceInteraction.vertexColor.rgb, f16vec3(1.0 / 255.0));
    float16_t maxColor = max(surfaceInteraction.vertexColor.r, max(surfaceInteraction.vertexColor.g, surfaceInteraction.vertexColor.b));
    surfaceInteraction.vertexColor.rgb /= maxColor;
    surfaceInteraction.vertexColor.rgb = mix(f16vec3(1), surfaceInteraction.vertexColor.rgb, float16_t(cb.vertexColorStrength));

    // Note: Gamma correct vertex color input.
    surfaceInteraction.vertexColor.rgb = gammaToLinear(surfaceInteraction.vertexColor.rgb);

    // Fixed function texture stage setting
    f16vec3 textureArg1 = f16vec3(1.0), textureArg2 = f16vec3(1.0);
    chooseTextureArgument(textureArg1, surface.textureColorArg1Source, albedo, surfaceInteraction.vertexColor.rgb, tFactor.rgb, f16vec3(1.0));
    chooseTextureArgument(textureArg2, surface.textureColorArg2Source, albedo, surfaceInteraction.vertexColor.rgb, tFactor.rgb, f16vec3(1.0));
    chooseTextureOperationColor(albedo, surface.textureColorOperation, textureArg1, textureArg2);
    if (surface.isTextureFactorBlend) {
      albedo *= tFactor.rgb;
    }
  }

  // Apply material modifiers/overrides
  albedo = saturate(albedo * cb.opaqueMaterialArgs.albedoScale + cb.opaqueMaterialArgs.albedoBias);

  if (cb.opaqueMaterialArgs.enableThinFilmOverride)
  {
    // Note: Thickness override is already normalized to the proper 0-1 range by the CPU to match how the albedo texture alpha channel encodes thickness.
    thinFilmThickness = cb.opaqueMaterialArgs.thinFilmNormalizedThicknessOverride;
  }

  // Load Normal

  f16vec3 normal = surfaceInteraction.interpolatedNormal;
  // Note: Defaults to 0 as this indicates no normal detail (which should be the case when a normal map is not present).
  float16_t normalDetail = 0.0h;

  if (normalLoaded)
  {
    f16vec3 tangentNormal;

    // Terrain baker produces decoded tangentNormal and (first) normal.
    if (isBakedTerrain)  
    {
      // REMIX-2224: Normals blended during terrain baking using programmable shaders can sometimes end up being invalid so we sanitize them at this point
      tangentNormal = sanitize(normalSample.xyz, cb.isZUp ? f16vec3(0.h, 0.h, 1.h) : f16vec3(0.h, 1.h, 0.h));
    }
    else // Decode encoded normal sample
    {
      // Note: Using f16 from texture to decode from is fine as the original texture is only 8 bits of precision.
      tangentNormal = unsignedOctahedralToHemisphereDirection(vec2(normalSample.xy), cb.opaqueMaterialArgs.normalIntensity);
    }
    
    const f16mat3 tangentToWorld = transpose(worldToTangent);

    normal = normalize(mul(tangentToWorld, tangentNormal));

    // REMIX-2224: Normals blended during terrain baking using programmable shaders can sometimes end up being invalid
    // after being transformed to world space so we sanitize them here
    if (isBakedTerrain) {
      normal = sanitize(normal, cb.isZUp ? f16vec3(0.h, 0.h, 1.h) : f16vec3(0.h, 1.h, 0.h));
    }

    // Note: Only factoring in the initial normal map read as part of the normal map calculation as the second normal acts blends in worldspace which
    // would re-introduce the potential for precision issues that we're trying to avoid in this calculation. Additionally, the second normal is only used
    // currently for water effects and is sampled from a less detailed mip, so it is likely not too relevant for "detail" in the normal map with regards
    // to what the normal detail is used for (denoiser disocclusion threshold modifications).
    normalDetail = 1.0h - tangentNormal.z; // Note: 1 - n.z == 1 - dot(n, vec3(0, 0, 1))

    if (secondNormalLoaded)
    {
      const f16vec3 tangentNormal2 = unsignedOctahedralToHemisphereDirection(vec2(secondNormalSample.xy), cb.opaqueMaterialArgs.normalIntensity);
      const f16vec3 normal2 = normalize(mul(tangentToWorld, tangentNormal2));

      normal = normalBlendRNM(normal2, normal);
    }
  }
  
#if defined(RAY_TRACING_PRIMARY_RAY) && defined(RAY_PIPELINE)
  if (cb.debugView == DEBUG_VIEW_OPAQUE_NORMAL_RESOLUTION_CHECKERS) 
  {
    storeColorOverlayedWithTextureResolutionCheckersInDebugView(normal, opaqueSurfaceMaterial.normalTextureIndex, surfaceInteraction);
  }
#endif
  // Load Tangent

  // Todo

  // Load Roughness

  float16_t roughness = opaqueSurfaceMaterial.roughnessConstant;

  if (roughnessLoaded)
  {
    roughness = roughnessSample.x;
  }

#if defined(RAY_TRACING_PRIMARY_RAY) && defined(RAY_PIPELINE)
  if (cb.debugView == DEBUG_VIEW_OPAQUE_ROUGHNESS_RESOLUTION_CHECKERS) 
  {
    storeColorOverlayedWithTextureResolutionCheckersInDebugView(roughness.xxx, opaqueSurfaceMaterial.roughnessTextureIndex, surfaceInteraction);
  }
#endif  
  // Apply material modifiers
  roughness = saturate(roughness * cb.opaqueMaterialArgs.roughnessScale + cb.opaqueMaterialArgs.roughnessBias);

  // Load Metallic

  float16_t metallic = opaqueSurfaceMaterial.metallicConstant;

  if (metallicLoaded)
  {
    metallic = metallicSample.x;
  }
    
  metallic = saturate(metallic * cb.opaqueMaterialArgs.metallicScale + cb.opaqueMaterialArgs.metallicBias);

  // Load Emissive Color

  f16vec3 emissiveColor = opaqueSurfaceMaterial.emissiveColorConstant;

  if (emissiveColorLoaded)
  {
    emissiveColor = emissiveColorSample.xyz;
  }

  // Note: Gamma correct emissive color input (be it from a constant or a texture). Currently assuming all textures are not using sRGB formats which
  // automatically do this conversion.
  // Todo: Disable this for when a sRGB texture is the source of the emissive color.
  emissiveColor = gammaToLinear(emissiveColor);

  // Transform to desired Opaque Material Interaction values

  // Note: Store a copy of the original albedo value so that operations later can use it rather than working off of the adjusted albedo
  // (which will not look correct on materials with weird blend modes that do things like invert alpha).
  const f16vec3 originalAlbedo = albedo;

  opaqueSurfaceMaterialInteraction.shadingNormal = getBentNormal(surfaceInteraction.triangleNormal, normal, -minimalRayInteraction.viewDirection);
  opaqueSurfaceMaterialInteraction.normalDetail = normalDetail;
  // Todo: Shading tangent/bitangent for anisotropy?
  opaqueSurfaceMaterialInteraction.opacity = opacity;
  opaqueSurfaceMaterialInteraction.thinFilmThickness = thinFilmThickness;

  // Note: Opacity factored into albedo and base reflectivity to ensure NEE and indirect lighting off of objects with opacity properly
  // account for how much light is being transmitted due to the opacity (similar to how Fresnel on glass works).
  opaqueSurfaceMaterialInteraction.albedo = surface.isMatte ? f16vec3(0) : albedoToAdjustedAlbedo(albedo, metallic, opacity);
  opaqueSurfaceMaterialInteraction.baseReflectivity = surface.isMatte ? f16vec3(0) : calcBaseReflectivity(albedo, metallic, opacity);
   
  // Note: Roughness loaded from texture is a perceptual roughness value (for optimal encoding), so this works as intended.
  calcRoughness(roughness, opaqueSurfaceMaterial.anisotropy,
    opaqueSurfaceMaterialInteraction.isotropicRoughness,
    opaqueSurfaceMaterialInteraction.anisotropicRoughness);

  f16vec3 derivedEmissiveColor;
  float16_t derivedEmissiveIntensity;

  // Note: "Fullbright", emissive blend modes and actual emissive color/intensity are mututally exclusive so this logic for selecting between them in this order is fine.
  if (surface.isEmissive)
  {
    // Todo: Remove this hack when a proper legacy material model is created, or find some better solution to it (such as setting emissive information on the CPU side).
    derivedEmissiveColor = originalAlbedo;
    derivedEmissiveIntensity = float16_t(2.0f); // Note: Arbitrary constant, should be set on the CPU side instead and controllable.
  }
  else if (surface.isEmissiveBlend && cb.enableEmissiveBlendEmissiveOverride)
  {
    // Note: Interpret original material's albedo as emissive color and the emissive blend override influence combined with an arbitrary constant as emissive intensity.
    // This is so that when "emissive" style blending is used it looks more correct in a physically based way based on the influence from the mode in question.
    // Todo: Move this all once separate Surface Materials for D3D9 compatability and normal usage are created.
    derivedEmissiveColor = originalAlbedo;
    derivedEmissiveIntensity = emissiveBlendOverrideInfluence * uint16BitsToHalf(cb.emissiveBlendOverrideEmissiveIntensity);
  }
  else
  {
    derivedEmissiveColor = emissiveColor;
    derivedEmissiveIntensity = opaqueSurfaceMaterial.emissiveIntensity;
  }

  derivedEmissiveIntensity *= uint16BitsToHalf(cb.emissiveIntensity); // Note: Global emissive intensity scalar on top of everything else.

  opaqueSurfaceMaterialInteraction.emissiveRadiance = derivedEmissiveColor * derivedEmissiveIntensity;

  opaqueSurfaceMaterialInteraction.subsurfaceMaterialInteraction =
    subSurfaceMaterialReadHelper(opaqueSurfaceMaterial.subsurfaceMaterialIndex, surfaceInteraction, opaqueSurfaceMaterial.samplerIndex);

  return opaqueSurfaceMaterialInteraction;
}

OpaqueSurfaceMaterialInteraction opaqueSurfaceMaterialInteractionCreate(PolymorphicSurfaceMaterialInteraction polymorphicSurfaceMaterialInteraction)
{
  // Decode the Opaque Surface Material Interaction from its polymorphic representation
  // Note: Opaque type is known in advance

  OpaqueSurfaceMaterialInteraction opaqueSurfaceMaterialInteraction;

  opaqueSurfaceMaterialInteraction.shadingNormal = polymorphicSurfaceMaterialInteraction.shadingNormal;
  opaqueSurfaceMaterialInteraction.emissiveRadiance = polymorphicSurfaceMaterialInteraction.emissiveRadiance;
  opaqueSurfaceMaterialInteraction.albedo = polymorphicSurfaceMaterialInteraction.vdata0;
  opaqueSurfaceMaterialInteraction.baseReflectivity = polymorphicSurfaceMaterialInteraction.vdata1;

  if (polymorphicSurfaceMaterialInteraction.fdata0 < 0.0)
  {
    opaqueSurfaceMaterialInteraction.opacity = 1.0;
    opaqueSurfaceMaterialInteraction.thinFilmThickness = -polymorphicSurfaceMaterialInteraction.fdata0;
  }
  else
  {
    opaqueSurfaceMaterialInteraction.opacity = polymorphicSurfaceMaterialInteraction.fdata0;
    opaqueSurfaceMaterialInteraction.thinFilmThickness = 0.0;
  }
  
  opaqueSurfaceMaterialInteraction.isotropicRoughness = polymorphicSurfaceMaterialInteraction.fdata1;
  opaqueSurfaceMaterialInteraction.anisotropicRoughness.x = polymorphicSurfaceMaterialInteraction.fdata2;
  opaqueSurfaceMaterialInteraction.anisotropicRoughness.y = polymorphicSurfaceMaterialInteraction.fdata3;
  opaqueSurfaceMaterialInteraction.normalDetail = polymorphicSurfaceMaterialInteraction.fdata4;
  opaqueSurfaceMaterialInteraction.subsurfaceMaterialInteraction.measurementDistance = polymorphicSurfaceMaterialInteraction.fdata5;
  opaqueSurfaceMaterialInteraction.subsurfaceMaterialInteraction.volumetricAnisotropy = polymorphicSurfaceMaterialInteraction.bdata1;
  opaqueSurfaceMaterialInteraction.subsurfaceMaterialInteraction.packedTransmittanceColor = polymorphicSurfaceMaterialInteraction.idata0;
  opaqueSurfaceMaterialInteraction.subsurfaceMaterialInteraction.packedSingleScatteringAlbedo = polymorphicSurfaceMaterialInteraction.idata1;

  opaqueSurfaceMaterialInteraction.flags = polymorphicSurfaceMaterialInteraction.bdata0;

  return opaqueSurfaceMaterialInteraction;
}

OpaqueSurfaceMaterialInteraction opaqueSurfaceMaterialInteractionCreate(
  GBufferMemoryPolymorphicSurfaceMaterialInteraction gBufferMemoryPolymorphicSurfaceMaterialInteraction)
{
  // Decode the Opaque Surface Material Interaction from its polymorphic GBuffer Memory representation
  // Note: Opaque type is known in advance

  OpaqueSurfaceMaterialInteraction opaqueSurfaceMaterialInteraction;

  const uint data0 = gBufferMemoryPolymorphicSurfaceMaterialInteraction.data0;
  const uint data1 = gBufferMemoryPolymorphicSurfaceMaterialInteraction.data1;

  const float16_t perceptualRoughness = gBufferMemoryPolymorphicSurfaceMaterialInteraction.perceptualRoughness;
  const float16_t sourceAnisotropy = snorm8ToF16(uint8_t(data0 >> 0));
  const float16_t opacityOrThinFilmThickness = unorm8ToF16(uint8_t(data0 >> 8));
  const uint8_t flagsAndType = uint8_t(data0 >> 24);
  const f16vec3 gammaEmissiveColor = f16vec3(
    unorm8ToF16(uint8_t(data0 >> 16)),
    unorm8ToF16(uint8_t(data1 >> 0)),
    unorm8ToF16(uint8_t(data1 >> 8)));
  const f16vec3 emissiveColor = gammaToLinearFast(gammaEmissiveColor);
  const float16_t emissiveIntensity = uint16BitsToHalf(uint16_t(data1 >> 16));

  float16_t isotropicRoughness;
  f16vec2 anisotropicRoughness;

  opaqueSurfaceMaterialInteraction.flags = flagsAndType & OPAQUE_SURFACE_MATERIAL_INTERACTION_FLAG_MASK;
  const bool thinFilmEnabled = (flagsAndType & OPAQUE_SURFACE_MATERIAL_INTERACTION_FLAG_USE_THIN_FILM_LAYER);

  calcRoughness(perceptualRoughness, sourceAnisotropy, isotropicRoughness, anisotropicRoughness);

  opaqueSurfaceMaterialInteraction.shadingNormal = gBufferMemoryPolymorphicSurfaceMaterialInteraction.worldShadingNormal;

  opaqueSurfaceMaterialInteraction.albedo = gBufferMemoryPolymorphicSurfaceMaterialInteraction.albedo;
  // Note: Opacity set to 1 when thin film is enabled (as we unfortunately cannot read from the opacity constant here and there
  // is no extra room in this GBuffer encoding to store both the opacity and the thin film thickness).
  opaqueSurfaceMaterialInteraction.opacity = thinFilmEnabled ? float16_t(1.0f) : opacityOrThinFilmThickness;
  opaqueSurfaceMaterialInteraction.baseReflectivity = gBufferMemoryPolymorphicSurfaceMaterialInteraction.baseReflectivity;
  opaqueSurfaceMaterialInteraction.isotropicRoughness = isotropicRoughness;
  opaqueSurfaceMaterialInteraction.anisotropicRoughness = anisotropicRoughness;
  opaqueSurfaceMaterialInteraction.emissiveRadiance = emissiveColor * emissiveIntensity;
  // Note: Thickness set to 0 when thin film is disabled for the same reason the opacity is set to 1 when it is enabled.
  opaqueSurfaceMaterialInteraction.thinFilmThickness = thinFilmEnabled ? opacityOrThinFilmThickness : float16_t(0.0f);

  // We don't store this in the G-buffer
  opaqueSurfaceMaterialInteraction.normalDetail = float16_t(0.0f);

  // Note thin opaque properties are stored later into PolymorphicSurfaceMaterialInteraction

  return opaqueSurfaceMaterialInteraction;
}

SurfaceMaterialInteractionLobeInformation opaqueSurfaceMaterialInteractionGetLobeInformation(
  OpaqueSurfaceMaterialInteraction opaqueSurfaceMaterialInteraction)
{
  SurfaceMaterialInteractionLobeInformation surfaceMaterialInteractionLobeInformation;

  surfaceMaterialInteractionLobeInformation.diffuseReflectionPresent =
    any(greaterThanEqual(opaqueSurfaceMaterialInteraction.albedo, albedoThreshold));
  surfaceMaterialInteractionLobeInformation.specularReflectionPresent =
    any(greaterThanEqual(opaqueSurfaceMaterialInteraction.baseReflectivity, baseReflectivityThreshold));
  surfaceMaterialInteractionLobeInformation.diffuseTransmissionPresent = false;
  surfaceMaterialInteractionLobeInformation.specularTransmissionPresent = false;

  surfaceMaterialInteractionLobeInformation.specularReflectionDirac =
    opaqueSurfaceMaterialInteraction.isotropicRoughness < roughnessThreshold;
  surfaceMaterialInteractionLobeInformation.specularTransmissionDirac = false;

  return surfaceMaterialInteractionLobeInformation;
}

bool opaqueSurfaceMaterialInteractionCalcLobeProbability(
  OpaqueSurfaceMaterialInteraction opaqueSurfaceMaterialInteraction,
  f16vec3 viewDirection,
  out float16_t diffuseReflectionProbability,
  out float16_t specularReflectionProbability,
  out float16_t opacityTransmissionProbability,
  out float16_t diffuseTransmissionProbability)
{
  // Calculate dot products used for evaluation

  const bool isSubsurface = isSubsurfaceMaterial(opaqueSurfaceMaterialInteraction);

  // Note: Normal dot output direction used as a "best" approximation in this case, usually aligned with the actual sampled
  // microfacet normal on surfaces with low roughness (identical at 0), but will become more and more potentially inaccurate
  // as roughness increases.
  const float16_t /* n.v */ normalDotOutputDirection =
    dot(opaqueSurfaceMaterialInteraction.shadingNormal, viewDirection);

  // Compute material-related quantities

  // Note: Albedo and Base Reflectivity already have opacity baked into them, though the fresnel contribution may still reach
  // 1 at grazing angles despite the low base reflectivity at normal incidence. Perceptual luminance also used for albedo and
  // base reflectivity to hopefully look better to the human eye than a simple average.
  const float16_t albedoLuminance = calcBt709Luminance(opaqueSurfaceMaterialInteraction.albedo);
  const f16vec3 fresnel =
    evalOpaqueSchlickFresnel(opaqueSurfaceMaterialInteraction.baseReflectivity, normalDotOutputDirection);
  const float16_t fresnelLuminance = calcBt709Luminance(fresnel);

  // Calculate lobe probabilities

  diffuseReflectionProbability = albedoLuminance;
  specularReflectionProbability = fresnelLuminance;
  opacityTransmissionProbability = 1.0h - opaqueSurfaceMaterialInteraction.opacity;
  diffuseTransmissionProbability = isSubsurface ? 1.0h - fresnelLuminance : 0.0h;

  // Todo: Pass raytraceArgs in in the future if accessing these constants poses a problem later.
  adjustProbabilityValue(
    diffuseReflectionProbability,
    uint16BitsToHalf(cb.opaqueDiffuseLobeSamplingProbabilityZeroThreshold),
    uint16BitsToHalf(cb.minOpaqueDiffuseLobeSamplingProbability));
  adjustProbabilityValue(
    specularReflectionProbability,
    uint16BitsToHalf(cb.opaqueSpecularLobeSamplingProbabilityZeroThreshold),
    uint16BitsToHalf(cb.minOpaqueSpecularLobeSamplingProbability));
  adjustProbabilityValue(
      opacityTransmissionProbability,
      uint16BitsToHalf(cb.opaqueOpacityTransmissionLobeSamplingProbabilityZeroThreshold),
      uint16BitsToHalf(cb.minOpaqueOpacityTransmissionLobeSamplingProbability));
  adjustProbabilityValue(
      diffuseTransmissionProbability,
      uint16BitsToHalf(cb.opaqueDiffuseTransmissionLobeSamplingProbabilityZeroThreshold),
      uint16BitsToHalf(cb.minOpaqueDiffuseTransmissionLobeSamplingProbability));

  const float16_t lobeProbabilitySum =
    opacityTransmissionProbability + diffuseTransmissionProbability + specularReflectionProbability + diffuseReflectionProbability;

  if (lobeProbabilitySum == float16_t(0.0f))
    return false;

  float16_t lobeProbabilityNormalizationFactor = 1.h / lobeProbabilitySum;
  diffuseReflectionProbability *= lobeProbabilityNormalizationFactor;
  specularReflectionProbability *= lobeProbabilityNormalizationFactor;
  opacityTransmissionProbability *= lobeProbabilityNormalizationFactor;
  diffuseTransmissionProbability *= lobeProbabilityNormalizationFactor;
  return true;
}

SurfaceMaterialInteractionLobeSample opaqueSurfaceMaterialInteractionCalcLobeSample(
  OpaqueSurfaceMaterialInteraction opaqueSurfaceMaterialInteraction,
  float16_t random,
  MinimalRayInteraction minimalRayInteraction,
  inout bool insideMedium)
{
  float16_t diffuseReflectionProbability = 0.0f;
  float16_t specularReflectionProbability = 0.0f;
  float16_t opacityTransmissionProbability = 0.0f;
  float16_t diffuseTransmissionProbability = 0.0f;
  bool isValid = opaqueSurfaceMaterialInteractionCalcLobeProbability(
    opaqueSurfaceMaterialInteraction, minimalRayInteraction.viewDirection,
    diffuseReflectionProbability, specularReflectionProbability, opacityTransmissionProbability, diffuseTransmissionProbability);

  SurfaceMaterialInteractionLobeSample surfaceMaterialInteractionLobeSample;
  if(!isValid)
  {
    // Note: Default to sampling specular lobe when no lobe desires to be sampled from. Ideally this could just be skipped entirely as
    // a sample though, but we currently do not support that logic, so for now we pick specular since it will generate more coherent
    // rays ideally to minimize the performance impact.
    surfaceMaterialInteractionLobeSample.lobe = opaqueLobeTypeSpecularReflection;
    surfaceMaterialInteractionLobeSample.pdf = float16_t(1.0f);
    return surfaceMaterialInteractionLobeSample;
  }

  // Sample a lobe

  const float16_t lobeSample = random;

  // Note: < used for conditions to ensure lobes never have a chance to be sampled from if their
  // probability is 0 (and to prevent NaNs from appearing due to 0 PDF).
  if (lobeSample < opacityTransmissionProbability)
  {
    surfaceMaterialInteractionLobeSample.lobe = opaqueLobeTypeOpacityTransmission;
    surfaceMaterialInteractionLobeSample.pdf = opacityTransmissionProbability;
  }
  else if (lobeSample < (opacityTransmissionProbability + diffuseTransmissionProbability)) {
    surfaceMaterialInteractionLobeSample.lobe = opaqueLobeTypeDiffuseTransmission;
    surfaceMaterialInteractionLobeSample.pdf = diffuseTransmissionProbability;
  }
  else if (lobeSample < (opacityTransmissionProbability + diffuseTransmissionProbability + specularReflectionProbability))
  {
    surfaceMaterialInteractionLobeSample.lobe = opaqueLobeTypeSpecularReflection;
    surfaceMaterialInteractionLobeSample.pdf = specularReflectionProbability;
  }
  else
  {
    surfaceMaterialInteractionLobeSample.lobe = opaqueLobeTypeDiffuseReflection;
    surfaceMaterialInteractionLobeSample.pdf = diffuseReflectionProbability;
  }

  return surfaceMaterialInteractionLobeSample;
}


// Note: Rejection sampling introduces bias which needs to be corrected before reenabling it
#define USE_REJECTION_SAMPLING 0

SurfaceMaterialInteractionSample opaqueSurfaceMaterialInteractionCalcDiffuseReflectionSample(
  OpaqueSurfaceMaterialInteraction opaqueSurfaceMaterialInteraction,
  inout RNG randomState,
  f16vec4 tangentToWorldSpaceQuaternion,
  MinimalRayInteraction minimalRayInteraction)
{
  const f16vec4 worldToTangentSpaceQuaternion = quaternionInverse(tangentToWorldSpaceQuaternion);

  // Set up relevant input vectors in tangent space

  const f16vec3 outputDirection = quaternionTransformVector(worldToTangentSpaceQuaternion, minimalRayInteraction.viewDirection);

  f16vec3 inputDirection;
  float cosineHemisphereSolidAnglePdf;
  float16_t /* l.v */ inputDirectionDotOutputDirection;
  float16_t /* n.l */ normalDotInputDirection;
  float16_t /* n.v */ normalDotOutputDirection;
  float16_t /* n.h */ normalDotMicrofacetNormal;

  // Random sampling may end up with an invalid sample, which will contribute 0 radiance to the output and bias the result to be darker
  // Apply rejection sampling on top by taking a few random sample attempts to find a valid sample instead
  // Max attempts set empirically, 2 attempts cleaned up 99%+ invalid samples, setting this to 5 was a safe upper bound to handle most dead samples
  int32_t sampleAttemptsRemaining = 5; 

#if USE_REJECTION_SAMPLING 
  while (sampleAttemptsRemaining-- > 0)
#else
  sampleAttemptsRemaining = -1;   // Mark sample as invalid - it's updated below
#endif
  {
    // Sample a new input direction based on a cosine weighted hemisphere

    const f16vec2 u = f16vec2(getNextSampleBlueNoise(randomState), getNextSampleBlueNoise(randomState));
    inputDirection = calcCosineHemisphereDirectionSample(u, cosineHemisphereSolidAnglePdf);

    // Todo: Sanity check if inputDirection is facing the wrong direction (Into the surface), currently this does not have much
    // effect and getting the triangle normal here requires a fairly high memory bandwidth cost, so for now it is not done

    // Calculate the microfacet normal from the input and output directions

    const f16vec3 microfacetNormal = normalize(outputDirection + inputDirection);

    // Calculate dot products used for evaluation
    // Note: Dot products against tangent space basis vectors are single components of the other vector

    /* l.v */ inputDirectionDotOutputDirection = dot(inputDirection, outputDirection);
    /* n.l */ normalDotInputDirection = inputDirection.z;
    /* n.v */ normalDotOutputDirection = outputDirection.z;
    /* n.h */ normalDotMicrofacetNormal = microfacetNormal.z;

    if (normalDotOutputDirection > 0.h && normalDotInputDirection > 0.h)
#if USE_REJECTION_SAMPLING 
      break;
#else
      sampleAttemptsRemaining = 1;
#endif      
  }
  
  // Failed to find a valid sample
  if (sampleAttemptsRemaining == -1)
  {
    SurfaceMaterialInteractionSample materialSample;

    materialSample.inputDirection = f16vec3(0.0, 0.0, 0.0);
    materialSample.throughput = f16vec3(0.0, 0.0, 0.0);
    materialSample.solidAnglePdf = 0.0f;

    return materialSample;
  }
  
  // Calculate the throughput of the sample

  const SubsurfaceMaterial subsurfaceMaterial = subsurfaceMaterialCreate(opaqueSurfaceMaterialInteraction.subsurfaceMaterialInteraction);
  const bool isSubsurface = isSubsurfaceMaterial(opaqueSurfaceMaterialInteraction);

  // If we have lambert diffuse transmission lobe, we are actually doing lambert sampling on the whole sphere, so the diffuse reflection weight should be weighted with 1/2pi for energy conservation.
  // The original hammon diffuse does sampling on hemisphere, so we can just normalize the weight again with 1/2.
  const f16vec3 lambertTransmissionWeight = (isSubsurface && subsurfaceMaterial.measurementDistance <= 0.05f) ? 0.5h : 1.0h;

  const f16vec3 weight =
    evalHammonDiffuse(opaqueSurfaceMaterialInteraction.albedo, opaqueSurfaceMaterialInteraction.isotropicRoughness,
      inputDirectionDotOutputDirection, normalDotInputDirection,
      normalDotOutputDirection, normalDotMicrofacetNormal) * lambertTransmissionWeight;
  f16vec3 throughput = safePositiveDivide(weight, f16vec3(cosineHemisphereSolidAnglePdf), materialEpsilon) *
    normalDotInputDirection;

  // Return the material sample

  SurfaceMaterialInteractionSample materialSample;

  materialSample.inputDirection = quaternionTransformVector(tangentToWorldSpaceQuaternion, inputDirection);
  materialSample.throughput = throughput;
  materialSample.solidAnglePdf = cosineHemisphereSolidAnglePdf;

  return materialSample;
}

// A copy of NRD_GetTrimmingFactor - avoids having a dependency on NRD.hlsli in the material system.
float calculateLobeTrimmingFactor(float roughness, float3 trimmingParams)
{
  return trimmingParams.x * smoothstep( trimmingParams.y, trimmingParams.z, roughness );
}

SurfaceMaterialInteractionSample opaqueSurfaceMaterialInteractionCalcSpecularReflectionSample(
  OpaqueSurfaceMaterialInteraction opaqueSurfaceMaterialInteraction,
  inout RNG randomState,
  f16vec4 tangentToWorldSpaceQuaternion,
  MinimalRayInteraction minimalRayInteraction)
{
  const f16vec4 worldToTangentSpaceQuaternion = quaternionInverse(tangentToWorldSpaceQuaternion);

  // Set up relevant input vectors in tangent space

  const f16vec3 outputDirection = quaternionTransformVector(worldToTangentSpaceQuaternion, minimalRayInteraction.viewDirection);

  // Calculate the specular lobe trimming factor based on roughness and NRD parameters.
  // Note: use the 'primaryIndirectNrd' parameter set because it is always controlled by the active indirect denoiser.
  // TODO: ideally this lobe trimming should only happen at the primary vertex, but there's likely no big difference.

  const float lobeTrimming = calculateLobeTrimmingFactor(
    opaqueSurfaceMaterialInteraction.isotropicRoughness, cb.primaryIndirectNrd.specularLobeTrimmingParams);

  f16vec3 inputDirection;

  float16_t /* v.h */ outputDirectionDotMicrofacetNormal;
  float16_t /* t.v */ tangentDotOutputDirection;
  float16_t /* b.v */ bitangentDotOutputDirection;
  float16_t /* n.v */ normalDotOutputDirection;
  float16_t /* t.l */ tangentDotInputDirection;
  float16_t /* b.l */ bitangentDotInputDirection;
  float16_t /* n.l */ normalDotInputDirection;
  float16_t /* t.h */ tangentDotMicrofacetNormal;
  float16_t /* b.h */ bitangentDotMicrofacetNormal;
  float16_t /* n.h */ normalDotMicrofacetNormal;
  
  // Random sampling may end up with an invalid sample, which will contribute 0 radiance to the output and bias the result to be darker
  // Apply rejection sampling on top by taking a few random sample attempts to find a valid sample instead
  // Max attempts set empirically, 3-4 attempts cleaned up 95%+ invalid samples
  // After 10 attempts there were only a handful pixels left with invalid samples, setting this to 15 was a safe upper bound to handle most pixels
  int32_t sampleAttemptsRemaining = 15; 

#if USE_REJECTION_SAMPLING
  while (sampleAttemptsRemaining-- > 0)
#else
  sampleAttemptsRemaining = -1;   // Mark sample as invalid - it's updated below
#endif
  {
    // Sample a new microfacet normal based on the distribution of visible normals

    const f16vec2 u = f16vec2(
      lobeTrimming * getNextSampleBlueNoise(randomState), 
      getNextSampleBlueNoise(randomState));
    const f16vec3 microfacetNormal = calcGGXVisibleNormalDistributionSample(opaqueSurfaceMaterialInteraction.anisotropicRoughness, outputDirection, u);

    // Reflect the output direction across the microfacet normal to get the input direction

    inputDirection = reflect(-outputDirection, microfacetNormal);

    // Todo: Sanity check if inputDirection is facing the wrong direction (Into the surface), currently this does not have much
    // effect and getting the triangle normal here requires a fairly high memory bandwidth cost, so for now it is not done

    // Calculate dot products used for evaluation
    // Note: Dot products against tangent space basis vectors are single components of the other vector

    /* v.h */ outputDirectionDotMicrofacetNormal = dot(outputDirection, microfacetNormal);
    /* t.v */ tangentDotOutputDirection = outputDirection.x;
    /* b.v */ bitangentDotOutputDirection = outputDirection.y;
    /* n.v */ normalDotOutputDirection = outputDirection.z;
    /* t.l */ tangentDotInputDirection = inputDirection.x;
    /* b.l */ bitangentDotInputDirection = inputDirection.y;
    /* n.l */ normalDotInputDirection = inputDirection.z;
    /* t.h */ tangentDotMicrofacetNormal = microfacetNormal.x;
    /* b.h */ bitangentDotMicrofacetNormal = microfacetNormal.y;
    /* n.h */ normalDotMicrofacetNormal = microfacetNormal.z;

    if (normalDotOutputDirection > 0.h && normalDotInputDirection > 0.h)
#if USE_REJECTION_SAMPLING 
      break;
#else
      sampleAttemptsRemaining = 1;
#endif      
  }
   
  // Failed to find a valid sample
  if (sampleAttemptsRemaining == -1)
  {
    SurfaceMaterialInteractionSample materialSample;

    materialSample.inputDirection = f16vec3(0.0, 0.0, 0.0);
    materialSample.throughput = f16vec3(0.0, 0.0, 0.0);
    materialSample.solidAnglePdf = 0.0f;

    return materialSample;
  }

  // Calculate the throughput of the sample

  const f16vec3 fresnel = evalOpaqueSchlickFresnel(
    opaqueSurfaceMaterialInteraction.baseReflectivity, outputDirectionDotMicrofacetNormal);

  // Todo: Pass in a material mode similar to the resolve mode to control this sort of material simplification option.
#ifdef OPAQUE_MATERIAL_USE_THIN_FILM
  // Note: Compute an approximate refractive index for the material for the thin film math, currently assuming the opaque material is always
  // surrounded by a vacuum (not true in all cases but good enough for this approximation).
  const float16_t refractiveIndex = baseReflectivityToIoR(
    materialIoRVacuum, calcBt709Luminance(opaqueSurfaceMaterialInteraction.baseReflectivity));
  const bool useThinFilm = opaqueSurfaceMaterialInteraction.thinFilmThickness > 0.0;
  const float16_t thinFilmThickness = opaqueSurfaceMaterialInteraction.thinFilmThickness * OPAQUE_SURFACE_MATERIAL_THIN_FILM_MAX_THICKNESS; // convert [0,1] range to nm
  // Note: Matching the refractive index calculation, compute the thin film assuming the material is surrounded by a vacuum and with a fixed layer IoR.
  const f16vec3 thinFilmFresnel = evalThinFilmFresnel(
    materialIoRVacuum, materialIoRThinFilmLayer, refractiveIndex,
    thinFilmThickness, outputDirectionDotMicrofacetNormal);

  const f16vec3 finalFresnel = useThinFilm ? thinFilmFresnel : fresnel;
#else
  const f16vec3 finalFresnel = fresnel;
#endif

  const float16_t outputGGXShadowing = evalGGXShadowing(
    opaqueSurfaceMaterialInteraction.anisotropicRoughness,
    tangentDotOutputDirection, bitangentDotOutputDirection, normalDotOutputDirection);
  const float16_t inputGGXShadowing = evalGGXShadowing(
    opaqueSurfaceMaterialInteraction.anisotropicRoughness,
    tangentDotInputDirection, bitangentDotInputDirection, normalDotInputDirection);
  // Note: Algebraic simplification of height correlated G2/G1 to reduce evaluation cost.
  // [Heitz 2015, "Implementing a Simple Anisotropic Rough Diffuse Material with Stochastic Evaluation"]
  const float16_t G2OverG1 = safePositiveDivide(
    inputGGXShadowing,
    inputGGXShadowing + outputGGXShadowing - (inputGGXShadowing * outputGGXShadowing),
    materialEpsilon);
  // Note: Simplified version of (weight / solidAnglePdf) * (n.l) when sampling from the distribution of
  // visible normals.
  // [Heitz 2014, "Importance sampling microfacet-based BSDFs using the distribution of visible normals"]
  const f16vec3 throughput = finalFresnel * G2OverG1; 

  // Calculate the solid angle PDF of the sample

  const float solidAnglePdf = evalGGXVisibleNormalDistributionSamplePdf(
    opaqueSurfaceMaterialInteraction.anisotropicRoughness,
    tangentDotOutputDirection, bitangentDotOutputDirection, normalDotOutputDirection,
    tangentDotMicrofacetNormal, bitangentDotMicrofacetNormal, normalDotMicrofacetNormal,
    outputDirectionDotMicrofacetNormal);

  // Return the material sample

  SurfaceMaterialInteractionSample materialSample;

  materialSample.inputDirection = quaternionTransformVector(tangentToWorldSpaceQuaternion, inputDirection);
  materialSample.throughput = throughput;
  materialSample.solidAnglePdf = solidAnglePdf;

  return materialSample;
}

SurfaceMaterialInteractionSample opaqueSurfaceMaterialInteractionCalcDiffuseTransmissionSample(
  OpaqueSurfaceMaterialInteraction opaqueSurfaceMaterialInteraction,
  inout RNG randomState,
  f16vec4 tangentToWorldSpaceQuaternion,
  MinimalRayInteraction minimalRayInteraction,
  inout bool insideMedium, inout bool penetrateSurface)
{
  const f16vec4 worldToTangentSpaceQuaternion = quaternionInverse(tangentToWorldSpaceQuaternion);

  // Set up relevant input vectors in tangent space

  const f16vec3 outputDirection = quaternionTransformVector(worldToTangentSpaceQuaternion, minimalRayInteraction.viewDirection);

  const f16vec2 u = f16vec2(getNextSampleBlueNoise(randomState), getNextSampleBlueNoise(randomState));
  float cosineHemisphereSolidAnglePdf = 0.0f;
  f16vec3 inputDirection = -calcCosineHemisphereDirectionSample(u, cosineHemisphereSolidAnglePdf);

  const float16_t /* l.h */ inputDirectionDotMicrofacetNormal = -inputDirection.z;
  const float16_t /* o.h */ outputDirectionDotMicrofacetNormal = outputDirection.z;

  const f16vec3 fresnel = evalOpaqueSchlickFresnel(
    opaqueSurfaceMaterialInteraction.baseReflectivity, outputDirectionDotMicrofacetNormal);
  const f16vec3 transmissionFresnel = f16vec3(1.0h, 1.0h, 1.0h) - fresnel;

  SurfaceMaterialInteractionSample materialSample;
  materialSample.inputDirection = quaternionTransformVector(tangentToWorldSpaceQuaternion, inputDirection);
  materialSample.throughput = safePositiveDivide(transmissionFresnel * opaqueSurfaceMaterialInteraction.albedo * rcp(twoPi), f16vec3(cosineHemisphereSolidAnglePdf), materialEpsilon) * inputDirectionDotMicrofacetNormal;
  materialSample.solidAnglePdf = cosineHemisphereSolidAnglePdf;

  // Note: Transmission rays penetrate the surface like translucent materials.
  penetrateSurface = true;

  return materialSample;
}

SurfaceMaterialInteractionSample thinOpaqueSurfaceMaterialInteractionCalcDiffuseTransmissionSample(
  OpaqueSurfaceMaterialInteraction opaqueSurfaceMaterialInteraction,
  inout RNG randomState,
  f16vec4 tangentToWorldSpaceQuaternion,
  MinimalRayInteraction minimalRayInteraction,
  SubsurfaceMaterial subsurfaceMaterial,
  inout bool insideMedium, inout bool penetrateSurface)
{
  const f16vec4 worldToTangentSpaceQuaternion = quaternionInverse(tangentToWorldSpaceQuaternion);

  // Set up relevant input vectors in tangent space

  const f16vec3 outputDirection = quaternionTransformVector(worldToTangentSpaceQuaternion, minimalRayInteraction.viewDirection);

  const f16vec2 u = f16vec2(getNextSampleBlueNoise(randomState), getNextSampleBlueNoise(randomState));
  float cosineHemisphereSolidAnglePdf = 0.0f;
  const f16vec3 inputDirection = -calcCosineHemisphereDirectionSample(u, cosineHemisphereSolidAnglePdf);

  const float16_t /* n.v */ normalDotOutputDirection = outputDirection.z;
  // Note: Negative as input direction always points into surface
  const float16_t /*-n.l */ transmissionNormalDotInputDirection = -inputDirection.z;
  const float16_t /* v.l */ inputDirectionDotOutputDirection = dot(-outputDirection, inputDirection);

  const f16vec3 weight = evalHanrahanSingleScatteringDiffuseTransmission(
    opaqueSurfaceMaterialInteraction.baseReflectivity,
    subsurfaceMaterial.volumetricAttenuationCoefficient, subsurfaceMaterial.measurementDistance,
    subsurfaceMaterial.singleScatteringAlbedo, subsurfaceMaterial.volumetricAnisotropy,
    normalDotOutputDirection,
    transmissionNormalDotInputDirection,
    inputDirectionDotOutputDirection);

  if (all(weight == 0.0h))
  {
    SurfaceMaterialInteractionSample materialSample;
    materialSample.inputDirection = f16vec3(0.0h, 0.0h, 0.0h);
    materialSample.throughput = f16vec3(0.0h, 0.0h, 0.0h);
    materialSample.solidAnglePdf = 0.0h;

    penetrateSurface = false;

    return materialSample;
  }

  SurfaceMaterialInteractionSample materialSample;
  materialSample.inputDirection = quaternionTransformVector(tangentToWorldSpaceQuaternion, inputDirection);
  materialSample.throughput = safePositiveDivide(weight, f16vec3(cosineHemisphereSolidAnglePdf), materialEpsilon) * transmissionNormalDotInputDirection;
  materialSample.solidAnglePdf = cosineHemisphereSolidAnglePdf;

  // Note: Transmission rays penetrate the surface like translucent materials.
  penetrateSurface = true;

  return materialSample;
}

// Note: Special case lobe for opacity.
SurfaceMaterialInteractionSample opaqueSurfaceMaterialInteractionCalcOpacityTransmissionSample(
  OpaqueSurfaceMaterialInteraction opaqueSurfaceMaterialInteraction,
  MinimalRayInteraction minimalRayInteraction,
  inout bool insideMedium, inout bool penetrateSurface)
{
  SurfaceMaterialInteractionSample materialSample;

  materialSample.inputDirection = -minimalRayInteraction.viewDirection;
  materialSample.throughput = f16vec3(
    float16_t(1.0f) - opaqueSurfaceMaterialInteraction.opacity,
    float16_t(1.0f) - opaqueSurfaceMaterialInteraction.opacity,
    float16_t(1.0f) - opaqueSurfaceMaterialInteraction.opacity);
  // Note: Dirac delta PDF, always a probability of 1 to sample this singular direction.
  materialSample.solidAnglePdf = 1.0f;

  // Note: Opacity rays penetrate the surface like translucent materials.
  penetrateSurface = true;

  return materialSample;
}

void opaqueSurfaceMaterialInteractionCalcSample(
  OpaqueSurfaceMaterialInteraction opaqueSurfaceMaterialInteraction,
  float16_t lobeRandom,
  inout RNG randomState,
  f16vec4 tangentToWorldSpaceQuaternion,
  MinimalRayInteraction minimalRayInteraction,
  inout SurfaceMaterialInteractionSample surfaceMaterialInteractionSample,
  inout SurfaceMaterialInteractionLobeSample surfaceMaterialInteractionLobeSample,
  inout bool insideMedium, inout bool penetrateSurface)
{
  surfaceMaterialInteractionLobeSample = opaqueSurfaceMaterialInteractionCalcLobeSample(
    opaqueSurfaceMaterialInteraction, lobeRandom, minimalRayInteraction, insideMedium);

  switch (uint(surfaceMaterialInteractionLobeSample.lobe))
  {
  default:
  case uint(opaqueLobeTypeDiffuseReflection):
    surfaceMaterialInteractionSample = opaqueSurfaceMaterialInteractionCalcDiffuseReflectionSample(
      opaqueSurfaceMaterialInteraction, randomState, tangentToWorldSpaceQuaternion, minimalRayInteraction);

    break;
  case uint(opaqueLobeTypeSpecularReflection):
    surfaceMaterialInteractionSample = opaqueSurfaceMaterialInteractionCalcSpecularReflectionSample(
      opaqueSurfaceMaterialInteraction, randomState, tangentToWorldSpaceQuaternion, minimalRayInteraction);

    break;
  case uint(opaqueLobeTypeOpacityTransmission):
    surfaceMaterialInteractionSample = opaqueSurfaceMaterialInteractionCalcOpacityTransmissionSample(
      opaqueSurfaceMaterialInteraction, minimalRayInteraction, insideMedium, penetrateSurface);

    break;
  case uint(opaqueLobeTypeDiffuseTransmission):
    // Load Subsurface Material
    const SubsurfaceMaterial subsurfaceMaterial = subsurfaceMaterialCreate(opaqueSurfaceMaterialInteraction.subsurfaceMaterialInteraction);

    // When the thickness of surface is thinner than this experimental threshold, we don't need to consider the volume of the surface.
    // Instead, we use a cheaper 2-side sampling method with traditional LambertBTDF to simulate the effect.
    if (subsurfaceMaterial.measurementDistance > 0.05f)
    {
      surfaceMaterialInteractionSample = thinOpaqueSurfaceMaterialInteractionCalcDiffuseTransmissionSample(
        opaqueSurfaceMaterialInteraction, randomState, tangentToWorldSpaceQuaternion, minimalRayInteraction, subsurfaceMaterial, insideMedium, penetrateSurface);
    }
    else
    {
      surfaceMaterialInteractionSample = opaqueSurfaceMaterialInteractionCalcDiffuseTransmissionSample(
        opaqueSurfaceMaterialInteraction, randomState, tangentToWorldSpaceQuaternion, minimalRayInteraction, insideMedium, penetrateSurface);
    }

    break;
  }
}

SurfaceMaterialInteractionPSRSample opaqueSurfaceMaterialInteractionCalcPSRReflectionSample(
  OpaqueSurfaceMaterialInteraction opaqueSurfaceMaterialInteraction,
  MinimalRayInteraction minimalRayInteraction)
{
  // Determine if Reflection PSR should happen based on the lobe information

  const SurfaceMaterialInteractionLobeInformation lobeInformation =
    opaqueSurfaceMaterialInteractionGetLobeInformation(opaqueSurfaceMaterialInteraction);

  // Note: Indicate reflection PSR should occur only if no diffuse lobe is present (to prevent
  // the need to split paths) and if a specular dirac lobe is present.
  if (
    lobeInformation.diffuseReflectionPresent ||
    !lobeInformation.specularReflectionPresent ||
    !lobeInformation.specularReflectionDirac ||
    any(opaqueSurfaceMaterialInteraction.emissiveRadiance > 0.0)
  )
  {
    SurfaceMaterialInteractionPSRSample materialPSRSample;
    materialPSRSample.performPSR = false;

    return materialPSRSample;
  }

  // Set up relevant input vectors

  const f16vec3 normal = opaqueSurfaceMaterialInteraction.shadingNormal;
  const f16vec3 outputDirection = minimalRayInteraction.viewDirection;

  // Calculate the microfacet normal
  // Note: Typically the microfacet normal would be sampled from so this would be known upfront in a sampling
  // method, due to being a dirac distribution though we always know it'll be the same as the normal.

  const f16vec3 microfacetNormal = normal;

  // Reflect the output direction across the microfacet normal to get the input direction

  const f16vec3 inputDirection = reflect(-outputDirection, microfacetNormal);

  // Calculate dot products used for evaluation

  const float16_t /* v.h */ outputDirectionDotMicrofacetNormal = dot(outputDirection, microfacetNormal);
  const float16_t /* n.v */ normalDotOutputDirection = outputDirectionDotMicrofacetNormal;
  const float16_t /* n.l */ normalDotInputDirection = dot(inputDirection, normal);

  if (normalDotOutputDirection <= float16_t(0.0) || normalDotInputDirection <= float16_t(0.0))
  {
    SurfaceMaterialInteractionPSRSample materialPSRSample;

    materialPSRSample.performPSR = false;

    return materialPSRSample;
  }

  // Calculate the attenuation of the sample

  const f16vec3 fresnel = evalOpaqueSchlickFresnel(
    opaqueSurfaceMaterialInteraction.baseReflectivity, outputDirectionDotMicrofacetNormal);

  // Todo: Pass in a material mode similar to the resolve mode to control this sort of material simplification option.
#ifdef OPAQUE_MATERIAL_USE_THIN_FILM
  // Note: Compute an approximate refractive index for the material for the thin film math, currently assuming the opaque material is always
  // surrounded by a vacuum (not true in all cases but good enough for this approximation).
  const float16_t refractiveIndex = baseReflectivityToIoR(
    materialIoRVacuum, calcBt709Luminance(opaqueSurfaceMaterialInteraction.baseReflectivity));
  const bool useThinFilm = opaqueSurfaceMaterialInteraction.thinFilmThickness > 0.0;
  const float16_t thinFilmThickness = opaqueSurfaceMaterialInteraction.thinFilmThickness * OPAQUE_SURFACE_MATERIAL_THIN_FILM_MAX_THICKNESS; // convert [0,1] range to nm
  // Note: Matching the refractive index calculation, compute the thin film assuming the material is surrounded by a vacuum and with a fixed layer IoR.
  const f16vec3 thinFilmFresnel = evalThinFilmFresnel(
    materialIoRVacuum, materialIoRThinFilmLayer, refractiveIndex,
    thinFilmThickness, outputDirectionDotMicrofacetNormal);

  const f16vec3 finalFresnel = useThinFilm ? thinFilmFresnel : fresnel;
#else
  const f16vec3 finalFresnel = fresnel;
#endif

  const f16vec3 attenuation = finalFresnel;

  // Return the material sample

  SurfaceMaterialInteractionPSRSample materialPSRSample;

  materialPSRSample.performPSR = true;
  materialPSRSample.useAlternateDisocclusionThreshold = opaqueSurfaceMaterialInteraction.normalDetail > float16_t(cb.psrrNormalDetailThreshold);
  materialPSRSample.inputDirection = inputDirection;
  materialPSRSample.attenuation = attenuation;
  materialPSRSample.vectorTransform = getReflectionMatrix(microfacetNormal);

  return materialPSRSample;
}

SurfaceMaterialInteractionPSRSample opaqueSurfaceMaterialInteractionCalcPSRTransmissionSample(
  OpaqueSurfaceMaterialInteraction opaqueSurfaceMaterialInteraction,
  MinimalRayInteraction minimalRayInteraction,
  inout bool insideMedium, inout bool penetrateSurface)
{
  SurfaceMaterialInteractionPSRSample materialPSRSample;

  // Todo: Experimentally test transmission PSR for opacity in the future, for now not needed though.
  materialPSRSample.performPSR = false;

  return materialPSRSample;
}

void opaqueSurfaceMaterialInteractionCalcPSRSample(
  OpaqueSurfaceMaterialInteraction opaqueSurfaceMaterialInteraction,
  MinimalRayInteraction minimalRayInteraction,
  inout SurfaceMaterialInteractionPSRSample surfaceMaterialInteractionReflectionPSRSample,
  inout SurfaceMaterialInteractionPSRSample surfaceMaterialInteractionTransmissionPSRSample,
  inout f16vec3 diffuseLayerWeight,
  inout bool reflectionSelectedIntegrationSurface,
  inout float16_t selectedIntegrationSurfacePdf,
  inout bool insideMedium, inout bool penetrateSurface)
{
  // Sample Reflection PSR

  surfaceMaterialInteractionReflectionPSRSample = opaqueSurfaceMaterialInteractionCalcPSRReflectionSample(
    opaqueSurfaceMaterialInteraction, minimalRayInteraction);

  // Sample Transmission PSR

  surfaceMaterialInteractionTransmissionPSRSample = opaqueSurfaceMaterialInteractionCalcPSRTransmissionSample(
    opaqueSurfaceMaterialInteraction, minimalRayInteraction, insideMedium, penetrateSurface);

  // Determine which PSR surface should be selected for integration and the probability of this choice

  // Note: Reflection PSR is the only thing that can realistically happen in the opaque material currently.
  if (surfaceMaterialInteractionReflectionPSRSample.performPSR)
  {
    reflectionSelectedIntegrationSurface = true;
    selectedIntegrationSurfacePdf = 1.0f;
  }
  else // Implicitly: if (surfaceMaterialInteractionTransmissionPSRSample.performPSR)
  {
    reflectionSelectedIntegrationSurface = false;
    selectedIntegrationSurfacePdf = 1.0f;
  }
}

float opaqueSurfaceMaterialInteractionCalcDiffuseReflectionSolidAnglePdf(
  OpaqueSurfaceMaterialInteraction opaqueSurfaceMaterialInteraction,
  MinimalRayInteraction minimalRayInteraction,
  f16vec3 inputDirection)
{
  float cosTheta = dot(inputDirection, opaqueSurfaceMaterialInteraction.shadingNormal);
  float solidAnglePdf = getCosineHemisphereSolidAnglePdf(saturate(cosTheta));

  return solidAnglePdf;
}

float opaqueSurfaceMaterialInteractionCalcSpecularReflectionSolidAnglePdf(
  OpaqueSurfaceMaterialInteraction opaqueSurfaceMaterialInteraction,
  MinimalRayInteraction minimalRayInteraction,
  f16vec3 worldInputDirection)
{

  const f16vec4 tangentToWorldSpaceQuaternion =
    quaternionCreateOrientation(materialTangentSpaceNormal, opaqueSurfaceMaterialInteraction.shadingNormal);
  const f16vec4 worldToTangentSpaceQuaternion = quaternionInverse(tangentToWorldSpaceQuaternion);

  // Set up relevant input vectors in tangent space
  const f16vec3 outputDirection = quaternionTransformVector(worldToTangentSpaceQuaternion, minimalRayInteraction.viewDirection);
  const f16vec3 inputDirection = quaternionTransformVector(worldToTangentSpaceQuaternion, worldInputDirection);

  // Calculate the specular lobe trimming factor based on roughness and NRD parameters.
  // Note: use the 'primaryIndirectNrd' parameter set because it is always controlled by the active indirect denoiser.
  // TODO: ideally this lobe trimming should only happen at the primary vertex, but there's likely no big difference.

  float16_t /* v.h */ outputDirectionDotMicrofacetNormal;
  float16_t /* t.v */ tangentDotOutputDirection;
  float16_t /* b.v */ bitangentDotOutputDirection;
  float16_t /* n.v */ normalDotOutputDirection;
  float16_t /* t.l */ tangentDotInputDirection;
  float16_t /* b.l */ bitangentDotInputDirection;
  float16_t /* n.l */ normalDotInputDirection;
  float16_t /* t.h */ tangentDotMicrofacetNormal;
  float16_t /* b.h */ bitangentDotMicrofacetNormal;
  float16_t /* n.h */ normalDotMicrofacetNormal;
  
  const f16vec3 microfacetNormal = normalize(inputDirection + outputDirection);

  // Todo: Sanity check if inputDirection is facing the wrong direction (Into the surface), currently this does not have much
  // effect and getting the triangle normal here requires a fairly high memory bandwidth cost, so for now it is not done

  // Calculate dot products used for evaluation
  // Note: Dot products against tangent space basis vectors are single components of the other vector

  /* v.h */ outputDirectionDotMicrofacetNormal = dot(outputDirection, microfacetNormal);
  /* t.v */ tangentDotOutputDirection = outputDirection.x;
  /* b.v */ bitangentDotOutputDirection = outputDirection.y;
  /* n.v */ normalDotOutputDirection = outputDirection.z;
  /* t.l */ tangentDotInputDirection = inputDirection.x;
  /* b.l */ bitangentDotInputDirection = inputDirection.y;
  /* n.l */ normalDotInputDirection = inputDirection.z;
  /* t.h */ tangentDotMicrofacetNormal = microfacetNormal.x;
  /* b.h */ bitangentDotMicrofacetNormal = microfacetNormal.y;
  /* n.h */ normalDotMicrofacetNormal = microfacetNormal.z;

  if (normalDotOutputDirection <= 0.h || normalDotInputDirection <= 0.h)
    return 0;

  // Calculate the solid angle PDF of the sample
  const float solidAnglePdf = evalGGXVisibleNormalDistributionSamplePdf(
    opaqueSurfaceMaterialInteraction.anisotropicRoughness,
    tangentDotOutputDirection, bitangentDotOutputDirection, normalDotOutputDirection,
    tangentDotMicrofacetNormal, bitangentDotMicrofacetNormal, normalDotMicrofacetNormal,
    outputDirectionDotMicrofacetNormal);

  return solidAnglePdf;
}

float opaqueSurfaceMaterialInteractionCalcDiffuseTransmissionSolidAnglePdf(
  OpaqueSurfaceMaterialInteraction opaqueSurfaceMaterialInteraction,
  MinimalRayInteraction minimalRayInteraction,
  f16vec3 inputDirection)
{
  float cosTheta = dot(-inputDirection, opaqueSurfaceMaterialInteraction.shadingNormal);
  float solidAnglePdf = getCosineHemisphereSolidAnglePdf(saturate(cosTheta));

  return solidAnglePdf;
}

float opaqueSurfaceMaterialInteractionCalcSolidAnglePdf(
  OpaqueSurfaceMaterialInteraction opaqueSurfaceMaterialInteraction,
  MinimalRayInteraction minimalRayInteraction,
  f16vec3 inputDirection)
{
  // Return the average of all the lobe PDFs
  // Note: Only lobes which are possible and specifically involved in reflections are included

  float16_t diffuseReflectionProbability = 0.0f;
  float16_t specularReflectionProbability = 0.0f;
  float16_t opacityTransmissionProbability = 0.0f;
  float16_t diffuseTransmissionProbability = 0.0f;
  bool isValid = opaqueSurfaceMaterialInteractionCalcLobeProbability(
    opaqueSurfaceMaterialInteraction, minimalRayInteraction.viewDirection,
    diffuseReflectionProbability, specularReflectionProbability, opacityTransmissionProbability, diffuseTransmissionProbability);

  float diffuseSolidAnglePdf = opaqueSurfaceMaterialInteractionCalcDiffuseReflectionSolidAnglePdf(opaqueSurfaceMaterialInteraction, minimalRayInteraction, inputDirection);
  float specularSolidAnglePdf = opaqueSurfaceMaterialInteractionCalcSpecularReflectionSolidAnglePdf(opaqueSurfaceMaterialInteraction, minimalRayInteraction, inputDirection);
  float diffuseTransmissionSolidAnglePdf = opaqueSurfaceMaterialInteractionCalcDiffuseTransmissionSolidAnglePdf(opaqueSurfaceMaterialInteraction, minimalRayInteraction, inputDirection);

  return diffuseSolidAnglePdf * diffuseReflectionProbability +
         specularSolidAnglePdf * specularReflectionProbability +
         diffuseTransmissionSolidAnglePdf * diffuseTransmissionProbability;
}


SurfaceMaterialInteractionSplitWeight opaqueSurfaceMaterialInteractionCalcApproxProjectedWeight(
  OpaqueSurfaceMaterialInteraction opaqueSurfaceMaterialInteraction,
  MinimalRayInteraction minimalRayInteraction,
  f16vec3 inputDirection)
{
  const f16vec3 microfacetNormal = normalize(inputDirection + minimalRayInteraction.viewDirection);
  const float16_t /* n.h */ normalDotMicrofacetNormal = dot(opaqueSurfaceMaterialInteraction.shadingNormal, microfacetNormal);
  const float16_t /* v.h */ outputDirectionDotMicrofacetNormal = dot(minimalRayInteraction.viewDirection, microfacetNormal);
  const float16_t /* n.l */ normalDotInputDirection = dot(inputDirection, opaqueSurfaceMaterialInteraction.shadingNormal);
  const float16_t /* n.v */ normalDotOutputDirection = dot(minimalRayInteraction.viewDirection, opaqueSurfaceMaterialInteraction.shadingNormal);

  // Load Subsurface Material
  const SubsurfaceMaterial subsurfaceMaterial = subsurfaceMaterialCreate(opaqueSurfaceMaterialInteraction.subsurfaceMaterialInteraction);
  const bool isSubsurface = isSubsurfaceMaterial(opaqueSurfaceMaterialInteraction);

  f16vec3 diffuseTransmissionWeight = f16vec3(0.0, 0.0, 0.0);
  if (isSubsurface)
  {
    diffuseTransmissionWeight = subsurfaceMaterial.singleScatteringAlbedo;
  }

  if (normalDotOutputDirection <= float16_t(0.0) || normalDotInputDirection <= float16_t(0.0))
  {
    SurfaceMaterialInteractionSplitWeight splitWeight;

    splitWeight.diffuseReflectionWeight = f16vec3(0.0, 0.0, 0.0);
    splitWeight.specularReflectionWeight = f16vec3(0.0, 0.0, 0.0);

    if (normalDotOutputDirection <= float16_t(0.0))
    {
      splitWeight.diffuseTransmissionWeight = f16vec3(0.0, 0.0, 0.0);
    }
    else
    {
      splitWeight.diffuseTransmissionWeight = diffuseTransmissionWeight * (-normalDotInputDirection);
    }

    return splitWeight;
  }

  // Calculate the weight
  const f16vec3 fresnel = evalOpaqueSchlickFresnel(opaqueSurfaceMaterialInteraction.baseReflectivity, outputDirectionDotMicrofacetNormal);
  const float16_t normalDistributionFunction = evalGGXNormalDistributionIsotropic(opaqueSurfaceMaterialInteraction.isotropicRoughness, normalDotMicrofacetNormal);
  const float16_t visibility = float16_t(1) / (float16_t(4) * normalDotInputDirection * normalDotOutputDirection);
  const f16vec3 diffuseReflectionWeight = opaqueSurfaceMaterialInteraction.albedo;
  const f16vec3 specularReflectionWeight = min(normalDistributionFunction * visibility * fresnel, f16vec3(float16Max));

  // Create a split weight
  SurfaceMaterialInteractionSplitWeight splitWeight;
  splitWeight.diffuseReflectionWeight = diffuseReflectionWeight * normalDotInputDirection;
  splitWeight.specularReflectionWeight = specularReflectionWeight * normalDotInputDirection;
  splitWeight.diffuseTransmissionWeight = f16vec3(0.0, 0.0, 0.0); // Will always be 0 when normalDotInputDirection >= 0

  return splitWeight;
}

SurfaceMaterialInteractionSplitWeight opaqueSurfaceMaterialInteractionCalcProjectedWeight(
  OpaqueSurfaceMaterialInteraction opaqueSurfaceMaterialInteraction,
  MinimalRayInteraction minimalRayInteraction,
  f16vec3 inputDirection)
{
  const f16vec4 tangentToWorldSpaceQuaternion =
    quaternionCreateOrientation(materialTangentSpaceNormal, opaqueSurfaceMaterialInteraction.shadingNormal);
  const f16vec4 worldToTangentSpaceQuaternion = quaternionInverse(tangentToWorldSpaceQuaternion);

  // Set up relevant input vectors in tangent space

  const f16vec3 tangentOutputDirection =
    quaternionTransformVector(worldToTangentSpaceQuaternion, minimalRayInteraction.viewDirection);
  const f16vec3 tangentInputDirection = quaternionTransformVector(worldToTangentSpaceQuaternion, inputDirection);

  // Calculate the microfacet normal from the input and output directions

  const f16vec3 microfacetNormal = normalize(tangentInputDirection + tangentOutputDirection);

  // Calculate dot products used for evaluation

  const float16_t /* l.v */ inputDirectionDotOutputDirection = dot(tangentInputDirection, tangentOutputDirection);
  const float16_t /* v.h */ outputDirectionDotMicrofacetNormal = dot(tangentOutputDirection, microfacetNormal);
  const float16_t /* t.v */ tangentDotOutputDirection = tangentOutputDirection.x;
  const float16_t /* b.v */ bitangentDotOutputDirection = tangentOutputDirection.y;
  const float16_t /* n.v */ normalDotOutputDirection = tangentOutputDirection.z;
  const float16_t /* t.l */ tangentDotInputDirection = tangentInputDirection.x;
  const float16_t /* b.l */ bitangentDotInputDirection = tangentInputDirection.y;
  const float16_t /* n.l */ normalDotInputDirection = tangentInputDirection.z;
  const float16_t /* t.h */ tangentDotMicrofacetNormal = microfacetNormal.x;
  const float16_t /* b.h */ bitangentDotMicrofacetNormal = microfacetNormal.y;
  const float16_t /* n.h */ normalDotMicrofacetNormal = microfacetNormal.z;
  const float16_t /*-n.l */ transmissionNormalDotInputDirection = -tangentInputDirection.z;

  // Load Subsurface Material
  const SubsurfaceMaterial subsurfaceMaterial = subsurfaceMaterialCreate(opaqueSurfaceMaterialInteraction.subsurfaceMaterialInteraction);
  const bool isSubsurface = isSubsurfaceMaterial(opaqueSurfaceMaterialInteraction);

  f16vec3 diffuseTransmissionWeight = f16vec3(0.0h, 0.0h, 0.0h);
  if (isSubsurface && normalDotOutputDirection > 0.0h) {
    diffuseTransmissionWeight = evalHanrahanSingleScatteringDiffuseTransmission(
      opaqueSurfaceMaterialInteraction.baseReflectivity,
      subsurfaceMaterial.volumetricAttenuationCoefficient, subsurfaceMaterial.measurementDistance,
      subsurfaceMaterial.singleScatteringAlbedo, subsurfaceMaterial.volumetricAnisotropy,
      normalDotOutputDirection,
      transmissionNormalDotInputDirection,
      inputDirectionDotOutputDirection);
  }

  if (normalDotOutputDirection <= 0.0h || normalDotInputDirection <= 0.0h)
  {
    SurfaceMaterialInteractionSplitWeight splitWeight;
    splitWeight.diffuseReflectionWeight = f16vec3(0.0, 0.0, 0.0);
    splitWeight.specularReflectionWeight = f16vec3(0.0, 0.0, 0.0);
    splitWeight.diffuseTransmissionWeight = diffuseTransmissionWeight * transmissionNormalDotInputDirection;

    return splitWeight;
  }

  // Calculate the weight

  const f16vec3 fresnel = evalOpaqueSchlickFresnel(
    opaqueSurfaceMaterialInteraction.baseReflectivity, outputDirectionDotMicrofacetNormal);

  // Todo: Pass in a material mode similar to the resolve mode to control this sort of material simplification option.
#ifdef OPAQUE_MATERIAL_USE_THIN_FILM
  // Note: Compute an approximate refractive index for the material for the thin film math, currently assuming the opaque material is always
  // surrounded by a vacuum (not true in all cases but good enough for this approximation).
  const float16_t refractiveIndex = baseReflectivityToIoR(
    materialIoRVacuum, calcBt709Luminance(opaqueSurfaceMaterialInteraction.baseReflectivity));
  const bool useThinFilm = opaqueSurfaceMaterialInteraction.thinFilmThickness > 0.0;
  const float16_t thinFilmThickness = opaqueSurfaceMaterialInteraction.thinFilmThickness * OPAQUE_SURFACE_MATERIAL_THIN_FILM_MAX_THICKNESS; // convert [0,1] range to nm
  // Note: Matching the refractive index calculation, compute the thin film assuming the material is surrounded by a vacuum and with a fixed layer IoR.
  const f16vec3 thinFilmFresnel = evalThinFilmFresnel(
    materialIoRVacuum, materialIoRThinFilmLayer, refractiveIndex,
    thinFilmThickness, outputDirectionDotMicrofacetNormal);

  const f16vec3 finalFresnel = useThinFilm ? thinFilmFresnel : fresnel;
#else
  const f16vec3 finalFresnel = fresnel;
#endif

  const float16_t normalDistributionFunction = evalGGXNormalDistribution(
    opaqueSurfaceMaterialInteraction.anisotropicRoughness,
    tangentDotMicrofacetNormal, bitangentDotMicrofacetNormal, normalDotMicrofacetNormal);
  const float16_t visibility = evalHeightCorrelatedGGXVisibility(
    opaqueSurfaceMaterialInteraction.anisotropicRoughness,
    tangentDotInputDirection, tangentDotOutputDirection, bitangentDotInputDirection,
    bitangentDotOutputDirection, normalDotInputDirection, normalDotOutputDirection);

  // Note: Thin film Fresnel not taken into account properly here. If we were using a simpler diffuse model where the transmission Fresnel was simply multiplied in somewhere
  // it'd be doable to incorporate like we do with specular, but currently the Hammon Diffuse model does Fresnel calculations internally based on various assumptions in its derivation
  // which makes it non-trivial to modify. This should be fine though as the thin film will only add a small bit of extra reflection in some cases (due to having two Fresnel layers),
  // or attenuate the reflected signal due to destructive interference, nothing major enough that'd majorly change the amount of transmitted light to make the diffuse contribution look very
  // wrong, though it may be slightly the wrong color in some instances, assuming that transmitted light interferes in the same way.
  const f16vec3 diffuseReflectionWeight = evalHammonDiffuse(
    opaqueSurfaceMaterialInteraction.albedo, opaqueSurfaceMaterialInteraction.isotropicRoughness,
    inputDirectionDotOutputDirection, normalDotInputDirection,
    normalDotOutputDirection, normalDotMicrofacetNormal);
  const f16vec3 specularReflectionWeight = min(finalFresnel * normalDistributionFunction * visibility, f16vec3(float16Max));

  // Create a split weight

  SurfaceMaterialInteractionSplitWeight splitWeight;

  splitWeight.diffuseReflectionWeight = diffuseReflectionWeight * normalDotInputDirection;
  splitWeight.specularReflectionWeight = specularReflectionWeight * normalDotInputDirection;
  splitWeight.diffuseTransmissionWeight = diffuseTransmissionWeight * normalDotInputDirection;

  return splitWeight;
}

f16vec3 opaqueSurfaceMaterialInteractionEvalEmissiveRadiance(
  OpaqueSurfaceMaterialInteraction opaqueSurfaceMaterialInteraction)
{
  return opaqueSurfaceMaterialInteraction.emissiveRadiance;
}

f16vec3 opaqueSurfaceMaterialGetAdjustedBaseReflectivity(
  OpaqueSurfaceMaterialInteraction opaqueSurfaceMaterialInteraction)
{
  // Note: Simple max taken between the specular reflection base reflectivity and a monochromatic "transmission" factor
  // based on the opacity to ensure if any contribution is in the specular lobe it will be properly represented.
  const f16vec3 adjustedBaseReflectivity = max(
    opaqueSurfaceMaterialInteraction.baseReflectivity,
    f16vec3(float16_t(1.0f) - opaqueSurfaceMaterialInteraction.opacity));

  return adjustedBaseReflectivity;
}

bool opaqueSurfaceMaterialInteractionHasHeightTexture(
  OpaqueSurfaceMaterialInteraction opaqueSurfaceMaterialInteraction)
{
  return opaqueSurfaceMaterialInteraction.flags & OPAQUE_SURFACE_MATERIAL_INTERACTION_FLAG_HAS_HEIGHT_TEXTURE;
}
